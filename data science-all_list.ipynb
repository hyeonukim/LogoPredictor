{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3179493e-6706-439f-84d4-752cbacf965d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUSINESS LOGO DOMAIN CLASSIFICATION\n",
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "Using device: cuda\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import os\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "import ast\n",
    "\n",
    "print(\"BUSINESS LOGO DOMAIN CLASSIFICATION\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42087470-cdfd-4041-b307-6ffe11fb9589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded 10000 samples\n",
      " Columns: ['uuid', 'name', 'type', 'permalink', 'cb_url', 'rank', 'created_at', 'updated_at', 'legal_name', 'roles', 'domain', 'homepage_url', 'region', 'city', 'address', 'postal_code', 'status', 'short_description', 'num_funding_rounds', 'total_funding_usd', 'total_funding', 'total_funding_currency_code', 'founded_on', 'last_funding_on', 'closed_on', 'employee_count', 'email', 'phone', 'facebook_url', 'linkedin_url', 'twitter_url', 'state_code', 'logo_url', 'country_code', 'category_groups_list', 'category_list', 'new_logo_url']\n",
      " Found 9998 logo files\n",
      "✓ Matched 9990 logos (99.9%)\n",
      " Logos with at least 1 category: 9990\n",
      "✓ Total unique categories (multi-label): 47\n",
      "✓ Total samples (logos with at least 1 matched file): 9990\n",
      "\n",
      "Category frequency distribution (based on individual categories):\n",
      "  Categories with 1 sample:      2861\n",
      "  Categories with 2-4 samples:   819\n",
      "  Categories with 5-9 samples:   200\n",
      "  Categories with 10-19 samples: 75\n",
      "  Categories with 20+ samples:   51\n",
      "\n",
      "Top 20 most common categories:\n",
      "  1. [5076] Software\n",
      "  2. [2378] Financial Services\n",
      "  3. [2301] Information Technology\n",
      "  4. [2043] Science and Engineering\n",
      "  5. [2007] Internet Services\n",
      "  6. [1893] Data and Analytics\n",
      "  7. [1720] Health Care\n",
      "  8. [1455] Hardware\n",
      "  9. [1373] Commerce and Shopping\n",
      " 10. [1373] Other\n",
      " 11. [1085] Artificial Intelligence\n",
      " 12. [1073] Mobile\n",
      " 13. [ 956] Lending and Investments\n",
      " 14. [ 903] Transportation\n",
      " 15. [ 863] Media and Entertainment\n",
      " 16. [ 810] Professional Services\n",
      " 17. [ 778] Sales and Marketing\n",
      " 18. [ 778] Biotechnology\n",
      " 19. [ 753] Apps\n",
      " 20. [ 688] Payments\n"
     ]
    }
   ],
   "source": [
    "csv_path = r\"C:\\BCIT\\data_science\\project\\LogoPredictor\\top10k_logos.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "logo_dir = r\"C:\\BCIT\\data_science\\project\\logo_images\"\n",
    "\n",
    "print(f\" Loaded {len(df)} samples\")\n",
    "print(f\" Columns: {df.columns.tolist()}\")\n",
    "\n",
    "# Get list of available logo files\n",
    "logo_files = os.listdir(logo_dir)\n",
    "logo_files_set = set(logo_files)\n",
    "print(f\" Found {len(logo_files)} logo files\")\n",
    "\n",
    "def clean_name(name):\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    name = str(name).lower().replace(' ', '_').replace('-', '_')\n",
    "    return ''.join(c for c in name if c.isalnum() or c == '_')\n",
    "\n",
    "df['clean_name'] = df['name'].apply(clean_name)\n",
    "\n",
    "\n",
    "matched_rows = []\n",
    "for logo_file in logo_files:\n",
    "    logo_name_raw = os.path.splitext(logo_file)[0]\n",
    "\n",
    "    # Many files may be like \"12345_company_name\", so drop leading ID part\n",
    "    if '_' in logo_name_raw:\n",
    "        logo_name = '_'.join(logo_name_raw.split('_', 1)[1:])\n",
    "    else:\n",
    "        logo_name = logo_name_raw\n",
    "    \n",
    "    logo_cleaned = clean_name(logo_name)\n",
    "    \n",
    "    # Find matching row in df\n",
    "    matches = df[df['clean_name'] == logo_cleaned]\n",
    "    if len(matches) > 0:\n",
    "        row = matches.iloc[0].copy()\n",
    "        row['logo_filename'] = logo_file\n",
    "        matched_rows.append(row)\n",
    "\n",
    "df_matched = pd.DataFrame(matched_rows)\n",
    "print(f\"✓ Matched {len(df_matched)} logos ({len(df_matched)/len(logo_files)*100:.1f}%)\")\n",
    "\n",
    "def parse_categories(x):\n",
    "    \"\"\"\n",
    "    Convert the raw category_groups_list string into a Python list.\n",
    "    Handles:\n",
    "      - \"['Software', 'AI']\"   (Python-list style)\n",
    "      - \"Software, AI\"        (comma-separated)\n",
    "      - NaNs                  (returns [])\n",
    "    \"\"\"\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    \n",
    "    x = str(x).strip()\n",
    "    \n",
    "    # Try to parse as Python list: \"['A', 'B']\"\n",
    "    if x.startswith('[') and x.endswith(']'):\n",
    "        try:\n",
    "            parsed = ast.literal_eval(x)\n",
    "            # Ensure list of strings\n",
    "            return [str(c).strip() for c in parsed]\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "    # Fallback: comma-separated string\n",
    "    return [c.strip() for c in x.split(',') if c.strip()]\n",
    "\n",
    "df_matched[\"parsed_categories\"] = df_matched[\"category_groups_list\"].apply(parse_categories)\n",
    "\n",
    "df_filtered = df_matched[df_matched[\"parsed_categories\"].map(len) > 0].copy()\n",
    "df_filtered = df_filtered.reset_index(drop=True)\n",
    "print(f\" Logos with at least 1 category: {len(df_filtered)}\")\n",
    "\n",
    "cat_counter = Counter()\n",
    "for cats in df_matched[\"parsed_categories\"]:\n",
    "    cat_counter.update(cats)\n",
    "\n",
    "# Convert to Series for convenience\n",
    "category_counts = pd.Series(cat_counter).sort_values(ascending=False)\n",
    "\n",
    "print(f\"✓ Total unique categories (multi-label): {len(category_counts)}\")\n",
    "print(f\"✓ Total samples (logos with at least 1 matched file): {len(df_matched)}\")\n",
    "\n",
    "# Distribution of category frequencies\n",
    "print(\"\\nCategory frequency distribution (based on individual categories):\")\n",
    "freq_values = df_matched['category_groups_list'].value_counts()\n",
    "print(f\"  Categories with 1 sample:      {(freq_values == 1).sum()}\")\n",
    "print(f\"  Categories with 2-4 samples:   {((freq_values >= 2) & (freq_values <= 4)).sum()}\")\n",
    "print(f\"  Categories with 5-9 samples:   {((freq_values >= 5) & (freq_values <= 9)).sum()}\")\n",
    "print(f\"  Categories with 10-19 samples: {((freq_values >= 10) & (freq_values < 20)).sum()}\")\n",
    "print(f\"  Categories with 20+ samples:   {(freq_values >= 20).sum()}\")\n",
    "\n",
    "print(\"\\nTop 20 most common categories:\")\n",
    "for i, (cat, count) in enumerate(category_counts.head(20).items(), 1):\n",
    "    short_cat = cat[:70] + \"...\" if len(cat) > 70 else cat\n",
    "    print(f\"{i:3d}. [{count:4d}] {short_cat}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "240508b3-4654-4781-896f-4e5b0f982ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ResNet18 features...\n",
      "  200/9990\n",
      "  400/9990\n",
      "  600/9990\n",
      "  800/9990\n",
      "  1000/9990\n",
      "  1200/9990\n",
      "  1400/9990\n",
      "  1600/9990\n",
      "  1800/9990\n",
      "  2000/9990\n",
      "  2200/9990\n",
      "  2400/9990\n",
      "  2600/9990\n",
      "  2800/9990\n",
      "  3000/9990\n",
      "  3200/9990\n",
      "  3400/9990\n",
      "  3600/9990\n",
      "  3800/9990\n",
      "  4000/9990\n",
      "  4200/9990\n",
      "  4400/9990\n",
      "  4600/9990\n",
      "  4800/9990\n",
      "  5000/9990\n",
      "  5200/9990\n",
      "  5400/9990\n",
      "  5600/9990\n",
      "  5800/9990\n",
      "  6000/9990\n",
      "  6200/9990\n",
      "  6400/9990\n",
      "  6600/9990\n",
      "  6800/9990\n",
      "  7000/9990\n",
      "  7200/9990\n",
      "  7400/9990\n",
      "  7600/9990\n",
      "  7800/9990\n",
      "  8000/9990\n",
      "  8200/9990\n",
      "  8400/9990\n",
      "  8600/9990\n",
      "  8800/9990\n",
      "  9000/9990\n",
      "  9200/9990\n",
      "  9400/9990\n",
      "  9600/9990\n",
      "  9800/9990\n",
      "\n",
      "Done. Extracted 9943 features (failed: 47)\n",
      " Feature matrix shape X: (9943, 512)\n",
      " df_features rows: 9943\n"
     ]
    }
   ],
   "source": [
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet = nn.Sequential(*list(resnet.children())[:-1])  # drop final FC layer\n",
    "resnet = resnet.to(device)\n",
    "resnet.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "features_list = []\n",
    "success_indices = []   # indices in df_filtered that succeeded\n",
    "failed = 0\n",
    "\n",
    "print(\"\\nExtracting ResNet18 features...\")\n",
    "with torch.no_grad():\n",
    "    for idx, row in df_filtered.iterrows():\n",
    "        logo_path = os.path.join(logo_dir, row[\"logo_filename\"])\n",
    "        try:\n",
    "            img = Image.open(logo_path).convert(\"RGB\")\n",
    "            img_tensor = transform(img).unsqueeze(0).to(device)  # [1,3,224,224]\n",
    "\n",
    "            # [1,512,1,1] -> [512]\n",
    "            feat = resnet(img_tensor).view(-1).cpu().numpy()\n",
    "            features_list.append(feat)\n",
    "            success_indices.append(idx)\n",
    "\n",
    "            if len(features_list) % 200 == 0:\n",
    "                print(f\"  {len(features_list)}/{len(df_filtered)}\")\n",
    "        except Exception:\n",
    "            failed += 1\n",
    "\n",
    "X = np.stack(features_list)   # [num_successful_logos, 512]\n",
    "df_features = df_filtered.loc[success_indices].reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nDone. Extracted {len(X)} features (failed: {failed})\")\n",
    "print(\" Feature matrix shape X:\", X.shape)\n",
    "print(\" df_features rows:\", len(df_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e34d516d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After exploding into (logo, category) pairs:\n",
      " X_expanded shape: (38012, 512)\n",
      " y length: 38012\n",
      " Example pairs:\n",
      "  logo_idx=0, category=Financial Services\n",
      "  logo_idx=0, category=Hardware\n",
      "  logo_idx=0, category=Internet Services\n",
      "  logo_idx=0, category=Lending and Investments\n",
      "  logo_idx=0, category=Mobile\n"
     ]
    }
   ],
   "source": [
    "tmp = df_features[[\"parsed_categories\"]].copy()\n",
    "tmp = tmp.explode(\"parsed_categories\")   # one row per (logo, category)\n",
    "tmp = tmp.rename(columns={\"parsed_categories\": \"category\"})\n",
    "tmp = tmp.reset_index().rename(columns={\"index\": \"logo_idx\"})\n",
    "# columns: ['logo_idx', 'category']\n",
    "# logo_idx now runs from 0 .. len(df_features)-1 and matches X\n",
    "\n",
    "logo_indices = tmp[\"logo_idx\"].values          # which row in X to use\n",
    "X_expanded = X[logo_indices]                   # [num_pairs, 512]\n",
    "y = tmp[\"category\"].values                     # [num_pairs]\n",
    "\n",
    "print(\"\\nAfter exploding into (logo, category) pairs:\")\n",
    "print(\" X_expanded shape:\", X_expanded.shape)\n",
    "print(\" y length:\", len(y))\n",
    "print(\" Example pairs:\")\n",
    "for i in range(5):\n",
    "    print(f\"  logo_idx={logo_indices[i]}, category={y[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "30e0ce17-aaf6-4971-89c0-a7118986fe35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 47 categories retained (single-label).\n",
      "  Samples per category: min=80, max=5052, mean=808.8\n",
      "\n",
      "Unique logos (after feature extraction): 9943\n",
      "\n",
      "Train rows: 30286, Test rows: 7726\n",
      "\n",
      "Train label distribution (first 10 classes):\n",
      "[ 382  226  125  592  864  632  136 1085  371  460]\n",
      "Test label distribution (first 10 classes):\n",
      "[104  53  34 156 218 142  27 280  93 130]\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "print(f\"\\n {len(le.classes_)} categories retained (single-label).\")\n",
    "binc = np.bincount(y_encoded)\n",
    "print(f\"  Samples per category: min={np.min(binc)}, max={np.max(binc)}, mean={np.mean(binc):.1f}\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_expanded)\n",
    "\n",
    "# Split by logo, so each logo is only in train OR test\n",
    "unique_logos = np.unique(logo_indices)\n",
    "print(f\"\\nUnique logos (after feature extraction): {len(unique_logos)}\")\n",
    "\n",
    "logo_train_ids, logo_test_ids = train_test_split(\n",
    "    unique_logos,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_mask = np.isin(logo_indices, logo_train_ids)\n",
    "test_mask  = np.isin(logo_indices, logo_test_ids)\n",
    "\n",
    "X_train = X_scaled[train_mask]\n",
    "y_train = y_encoded[train_mask]\n",
    "logo_train_split = logo_indices[train_mask]\n",
    "\n",
    "X_test  = X_scaled[test_mask]\n",
    "y_test  = y_encoded[test_mask]\n",
    "logo_test_split = logo_indices[test_mask]\n",
    "\n",
    "print(f\"\\nTrain rows: {len(X_train)}, Test rows: {len(X_test)}\")\n",
    "\n",
    "print(\"\\nTrain label distribution (first 10 classes):\")\n",
    "print(np.bincount(y_train)[:10])\n",
    "print(\"Test label distribution (first 10 classes):\")\n",
    "print(np.bincount(y_test)[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85962fa0",
   "metadata": {},
   "source": [
    "# Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1442528a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "def evaluate_membership_accuracy(model, X_train, y_train, X_test, y_test,\n",
    "                                 logo_train_split, logo_test_split, le, df_features,\n",
    "                                 name=\"MODEL\"):\n",
    "    print(f\"\\n\\n=== {name} — EVALUATION ===\")\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred  = model.predict(X_test)\n",
    "\n",
    "    print(f\"\\n{name} — ROW-LEVEL METRICS (exploded (logo, category) samples)\")\n",
    "\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    test_acc  = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    prec_w, rec_w, f1_w, _ = precision_recall_fscore_support(\n",
    "        y_test, y_test_pred, average=\"weighted\", zero_division=0\n",
    "    )\n",
    "    prec_m, rec_m, f1_m, _ = precision_recall_fscore_support(\n",
    "        y_test, y_test_pred, average=\"macro\", zero_division=0\n",
    "    )\n",
    "\n",
    "    print(f\"Train accuracy: {train_acc:.4f}\")\n",
    "    print(f\"Test  accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    print(\"\\nTest precision/recall/F1 (weighted):\")\n",
    "    print(f\"  Precision_w: {prec_w:.4f}\")\n",
    "    print(f\"  Recall_w:    {rec_w:.4f}\")\n",
    "    print(f\"  F1_w:        {f1_w:.4f}\")\n",
    "\n",
    "    print(\"\\nTest precision/recall/F1 (macro):\")\n",
    "    print(f\"  Precision_m: {prec_m:.4f}\")\n",
    "    print(f\"  Recall_m:    {rec_m:.4f}\")\n",
    "    print(f\"  F1_m:        {f1_m:.4f}\")\n",
    "\n",
    "    classes_in_test = np.unique(y_test)\n",
    "    target_names = le.inverse_transform(classes_in_test)\n",
    "    print(f\"\\n{name} — CLASSIFICATION REPORT (row-level)\")\n",
    "    print(\n",
    "        classification_report(\n",
    "            y_test,\n",
    "            y_test_pred,\n",
    "            labels=classes_in_test,\n",
    "            target_names=target_names,\n",
    "            digits=3,\n",
    "            zero_division=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(f\"\\n{name} — LOGO-LEVEL MEMBERSHIP ACCURACY\")\n",
    "\n",
    "    y_train_pred_labels = le.inverse_transform(y_train_pred)\n",
    "    train_unique_logos = np.unique(logo_train_split)\n",
    "    correct_train = 0\n",
    "\n",
    "    for logo_idx in train_unique_logos:\n",
    "        rows = np.where(logo_train_split == logo_idx)[0]\n",
    "        preds = y_train_pred_labels[rows]\n",
    "        true_cats = df_features.loc[logo_idx, \"parsed_categories\"]\n",
    "\n",
    "        if any(p in true_cats for p in preds):\n",
    "            correct_train += 1\n",
    "\n",
    "    train_membership_acc = correct_train / len(train_unique_logos)\n",
    "\n",
    "    y_test_pred_labels = le.inverse_transform(y_test_pred)\n",
    "    test_unique_logos = np.unique(logo_test_split)\n",
    "    correct_test = 0\n",
    "\n",
    "    for logo_idx in test_unique_logos:\n",
    "        rows = np.where(logo_test_split == logo_idx)[0]\n",
    "        preds = y_test_pred_labels[rows]\n",
    "        true_cats = df_features.loc[logo_idx, \"parsed_categories\"]\n",
    "\n",
    "        if any(p in true_cats for p in preds):\n",
    "            correct_test += 1\n",
    "\n",
    "    test_membership_acc = correct_test / len(test_unique_logos)\n",
    "\n",
    "    print(f\"\\n{name} — TRAIN membership accuracy:\")\n",
    "    print(f\"  {correct_train}/{len(train_unique_logos)} = {train_membership_acc:.4f}\")\n",
    "\n",
    "    print(f\"\\n{name} — TEST membership accuracy:\")\n",
    "    print(f\"  {correct_test}/{len(test_unique_logos)} = {test_membership_acc:.4f}\")\n",
    "\n",
    "    return train_membership_acc, test_membership_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b557de9e",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0ce5d677-ae08-4abb-bf66-78ce3d7754ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training RandomForestClassifier...\n",
      "\n",
      "\n",
      "=== RandomForest — EVALUATION ===\n",
      "\n",
      "RandomForest — ROW-LEVEL METRICS (exploded (logo, category) samples)\n",
      "Train accuracy: 0.2584\n",
      "Test  accuracy: 0.0325\n",
      "\n",
      "Test precision/recall/F1 (weighted):\n",
      "  Precision_w: 0.0549\n",
      "  Recall_w:    0.0325\n",
      "  F1_w:        0.0260\n",
      "\n",
      "Test precision/recall/F1 (macro):\n",
      "  Precision_m: 0.0290\n",
      "  Recall_m:    0.0404\n",
      "  F1_m:        0.0224\n",
      "\n",
      "RandomForest — CLASSIFICATION REPORT (row-level)\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "         Administrative Services      0.016     0.048     0.024       104\n",
      "                     Advertising      0.000     0.000     0.000        53\n",
      "         Agriculture and Farming      0.033     0.176     0.056        34\n",
      "                            Apps      0.033     0.096     0.049       156\n",
      "         Artificial Intelligence      0.017     0.014     0.015       218\n",
      "                   Biotechnology      0.037     0.437     0.068       142\n",
      "            Clothing and Apparel      0.032     0.185     0.055        27\n",
      "           Commerce and Shopping      0.030     0.007     0.012       280\n",
      "         Community and Lifestyle      0.021     0.022     0.021        93\n",
      "            Consumer Electronics      0.000     0.000     0.000       130\n",
      "                  Consumer Goods      0.035     0.049     0.041        61\n",
      "          Content and Publishing      0.000     0.000     0.000        61\n",
      "              Data and Analytics      0.040     0.010     0.016       399\n",
      "                          Design      0.013     0.010     0.011        96\n",
      "                       Education      0.012     0.033     0.017        92\n",
      "                          Energy      0.022     0.017     0.019        59\n",
      "                          Events      0.000     0.000     0.000        24\n",
      "              Financial Services      0.081     0.039     0.052       466\n",
      "               Food and Beverage      0.034     0.090     0.050       100\n",
      "                          Gaming      0.012     0.059     0.020        34\n",
      "         Government and Military      0.000     0.000     0.000        25\n",
      "                        Hardware      0.032     0.003     0.006       304\n",
      "                     Health Care      0.043     0.043     0.043       323\n",
      "          Information Technology      0.051     0.014     0.022       489\n",
      "               Internet Services      0.071     0.018     0.029       385\n",
      "         Lending and Investments      0.040     0.081     0.053       186\n",
      "                   Manufacturing      0.017     0.011     0.013        89\n",
      "         Media and Entertainment      0.000     0.000     0.000       170\n",
      "Messaging and Telecommunications      0.018     0.051     0.027        39\n",
      "                          Mobile      0.032     0.019     0.024       212\n",
      "                 Music and Audio      0.000     0.000     0.000        20\n",
      "               Natural Resources      0.000     0.000     0.000        29\n",
      "          Navigation and Mapping      0.012     0.050     0.020        20\n",
      "                           Other      0.033     0.014     0.019       290\n",
      "                        Payments      0.019     0.038     0.025       131\n",
      "                       Platforms      0.000     0.000     0.000        24\n",
      "            Privacy and Security      0.018     0.053     0.027       113\n",
      "           Professional Services      0.007     0.007     0.007       150\n",
      "                     Real Estate      0.026     0.073     0.039       110\n",
      "             Sales and Marketing      0.039     0.013     0.019       157\n",
      "         Science and Engineering      0.082     0.020     0.032       405\n",
      "                        Software      0.163     0.015     0.027      1019\n",
      "                          Sports      0.011     0.019     0.014        54\n",
      "                  Sustainability      0.125     0.016     0.028        64\n",
      "                  Transportation      0.041     0.031     0.035       192\n",
      "              Travel and Tourism      0.012     0.021     0.015        48\n",
      "                           Video      0.000     0.000     0.000        49\n",
      "\n",
      "                        accuracy                          0.032      7726\n",
      "                       macro avg      0.029     0.040     0.022      7726\n",
      "                    weighted avg      0.055     0.032     0.026      7726\n",
      "\n",
      "\n",
      "RandomForest — LOGO-LEVEL MEMBERSHIP ACCURACY\n",
      "\n",
      "RandomForest — TRAIN membership accuracy:\n",
      "  7827/7954 = 0.9840\n",
      "\n",
      "RandomForest — TEST membership accuracy:\n",
      "  251/1989 = 0.1262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9840331908473724, 0.12619406737053795)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=25,\n",
    "    min_samples_split=8,\n",
    "    min_samples_leaf=3,\n",
    "    max_features='sqrt',\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining RandomForestClassifier...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "evaluate_membership_accuracy(\n",
    "    model=model,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    logo_train_split=logo_train_split,\n",
    "    logo_test_split=logo_test_split,\n",
    "    le=le,\n",
    "    df_features=df_features,\n",
    "    name=\"RandomForest\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dc3e90",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "64b9c29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training LogisticRegression (OvR) on X_train...\n",
      "LogisticRegression training complete.\n",
      "\n",
      "\n",
      "=== LogisticRegression — EVALUATION ===\n",
      "\n",
      "LogisticRegression — ROW-LEVEL METRICS (exploded (logo, category) samples)\n",
      "Train accuracy: 0.0583\n",
      "Test  accuracy: 0.0157\n",
      "\n",
      "Test precision/recall/F1 (weighted):\n",
      "  Precision_w: 0.0493\n",
      "  Recall_w:    0.0157\n",
      "  F1_w:        0.0122\n",
      "\n",
      "Test precision/recall/F1 (macro):\n",
      "  Precision_m: 0.0239\n",
      "  Recall_m:    0.0315\n",
      "  F1_m:        0.0158\n",
      "\n",
      "LogisticRegression — CLASSIFICATION REPORT (row-level)\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "         Administrative Services      0.014     0.038     0.021       104\n",
      "                     Advertising      0.003     0.019     0.005        53\n",
      "         Agriculture and Farming      0.011     0.059     0.019        34\n",
      "                            Apps      0.029     0.019     0.023       156\n",
      "         Artificial Intelligence      0.046     0.018     0.026       218\n",
      "                   Biotechnology      0.074     0.120     0.091       142\n",
      "            Clothing and Apparel      0.018     0.185     0.033        27\n",
      "           Commerce and Shopping      0.037     0.004     0.007       280\n",
      "         Community and Lifestyle      0.017     0.054     0.026        93\n",
      "            Consumer Electronics      0.021     0.023     0.022       130\n",
      "                  Consumer Goods      0.015     0.066     0.024        61\n",
      "          Content and Publishing      0.006     0.033     0.010        61\n",
      "              Data and Analytics      0.000     0.000     0.000       399\n",
      "                          Design      0.009     0.021     0.013        96\n",
      "                       Education      0.008     0.022     0.011        92\n",
      "                          Energy      0.009     0.051     0.015        59\n",
      "                          Events      0.000     0.000     0.000        24\n",
      "              Financial Services      0.056     0.002     0.004       466\n",
      "               Food and Beverage      0.021     0.040     0.028       100\n",
      "                          Gaming      0.009     0.088     0.016        34\n",
      "         Government and Military      0.000     0.000     0.000        25\n",
      "                        Hardware      0.000     0.000     0.000       304\n",
      "                     Health Care      0.043     0.006     0.011       323\n",
      "          Information Technology      0.031     0.002     0.004       489\n",
      "               Internet Services      0.067     0.003     0.005       385\n",
      "         Lending and Investments      0.010     0.005     0.007       186\n",
      "                   Manufacturing      0.004     0.011     0.006        89\n",
      "         Media and Entertainment      0.030     0.006     0.010       170\n",
      "Messaging and Telecommunications      0.018     0.128     0.032        39\n",
      "                          Mobile      0.026     0.009     0.014       212\n",
      "                 Music and Audio      0.008     0.050     0.014        20\n",
      "               Natural Resources      0.006     0.034     0.010        29\n",
      "          Navigation and Mapping      0.000     0.000     0.000        20\n",
      "                           Other      0.000     0.000     0.000       290\n",
      "                        Payments      0.040     0.053     0.046       131\n",
      "                       Platforms      0.000     0.000     0.000        24\n",
      "            Privacy and Security      0.025     0.044     0.032       113\n",
      "           Professional Services      0.033     0.013     0.019       150\n",
      "                     Real Estate      0.026     0.055     0.035       110\n",
      "             Sales and Marketing      0.028     0.013     0.018       157\n",
      "         Science and Engineering      0.100     0.010     0.018       405\n",
      "                        Software      0.167     0.001     0.002      1019\n",
      "                          Sports      0.005     0.037     0.009        54\n",
      "                  Sustainability      0.014     0.062     0.022        64\n",
      "                  Transportation      0.031     0.016     0.021       192\n",
      "              Travel and Tourism      0.000     0.000     0.000        48\n",
      "                           Video      0.010     0.061     0.017        49\n",
      "\n",
      "                        accuracy                          0.016      7726\n",
      "                       macro avg      0.024     0.032     0.016      7726\n",
      "                    weighted avg      0.049     0.016     0.012      7726\n",
      "\n",
      "\n",
      "LogisticRegression — LOGO-LEVEL MEMBERSHIP ACCURACY\n",
      "\n",
      "LogisticRegression — TRAIN membership accuracy:\n",
      "  1767/7954 = 0.2222\n",
      "\n",
      "LogisticRegression — TEST membership accuracy:\n",
      "  121/1989 = 0.0608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2221523761629369, 0.06083459024635495)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(\n",
    "    multi_class=\"ovr\",\n",
    "    max_iter=2000,\n",
    "    C=1.0,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining LogisticRegression (OvR) on X_train...\")\n",
    "logreg.fit(X_train, y_train)\n",
    "print(\"LogisticRegression training complete.\")\n",
    "\n",
    "evaluate_membership_accuracy(\n",
    "    model=logreg,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    logo_train_split=logo_train_split,\n",
    "    logo_test_split=logo_test_split,\n",
    "    le=le,\n",
    "    df_features=df_features,\n",
    "    name=\"LogisticRegression\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186db7b2",
   "metadata": {},
   "source": [
    "# ResNet Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7e792f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training ResNet-style MLP head on embeddings...\n",
      "Epoch  1 | Train loss: 3.4478 | Train acc: 0.1235 | Test acc: 0.1319\n",
      "Epoch  2 | Train loss: 3.3154 | Train acc: 0.1324 | Test acc: 0.1323\n",
      "Epoch  3 | Train loss: 3.2193 | Train acc: 0.1359 | Test acc: 0.1178\n",
      "Epoch  4 | Train loss: 3.1111 | Train acc: 0.1369 | Test acc: 0.1211\n",
      "Epoch  5 | Train loss: 2.9800 | Train acc: 0.1394 | Test acc: 0.1139\n",
      "Epoch  6 | Train loss: 2.8627 | Train acc: 0.1454 | Test acc: 0.1152\n",
      "Epoch  7 | Train loss: 2.7523 | Train acc: 0.1467 | Test acc: 0.0972\n",
      "Epoch  8 | Train loss: 2.6609 | Train acc: 0.1509 | Test acc: 0.1017\n",
      "Epoch  9 | Train loss: 2.5784 | Train acc: 0.1509 | Test acc: 0.0994\n",
      "Epoch 10 | Train loss: 2.5076 | Train acc: 0.1541 | Test acc: 0.1021\n",
      "\n",
      "\n",
      "=== ResNet-MLP — EVALUATION ===\n",
      "\n",
      "ResNet-MLP — ROW-LEVEL METRICS (exploded (logo, category) samples)\n",
      "Train accuracy: 0.2259\n",
      "Test  accuracy: 0.1021\n",
      "\n",
      "Test precision/recall/F1 (weighted):\n",
      "  Precision_w: 0.0493\n",
      "  Recall_w:    0.1021\n",
      "  F1_w:        0.0545\n",
      "\n",
      "Test precision/recall/F1 (macro):\n",
      "  Precision_m: 0.0223\n",
      "  Recall_m:    0.0259\n",
      "  F1_m:        0.0187\n",
      "\n",
      "ResNet-MLP — CLASSIFICATION REPORT (row-level)\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "         Administrative Services      0.000     0.000     0.000       104\n",
      "                     Advertising      0.000     0.000     0.000        53\n",
      "         Agriculture and Farming      0.028     0.029     0.029        34\n",
      "                            Apps      0.000     0.000     0.000       156\n",
      "         Artificial Intelligence      0.019     0.005     0.007       218\n",
      "                   Biotechnology      0.000     0.000     0.000       142\n",
      "            Clothing and Apparel      0.000     0.000     0.000        27\n",
      "           Commerce and Shopping      0.042     0.043     0.042       280\n",
      "         Community and Lifestyle      0.000     0.000     0.000        93\n",
      "            Consumer Electronics      0.000     0.000     0.000       130\n",
      "                  Consumer Goods      0.050     0.016     0.025        61\n",
      "          Content and Publishing      0.000     0.000     0.000        61\n",
      "              Data and Analytics      0.025     0.005     0.008       399\n",
      "                          Design      0.000     0.000     0.000        96\n",
      "                       Education      0.000     0.000     0.000        92\n",
      "                          Energy      0.000     0.000     0.000        59\n",
      "                          Events      0.000     0.000     0.000        24\n",
      "              Financial Services      0.063     0.129     0.085       466\n",
      "               Food and Beverage      0.046     0.050     0.048       100\n",
      "                          Gaming      0.000     0.000     0.000        34\n",
      "         Government and Military      0.000     0.000     0.000        25\n",
      "                        Hardware      0.057     0.016     0.026       304\n",
      "                     Health Care      0.078     0.115     0.092       323\n",
      "          Information Technology      0.071     0.033     0.045       489\n",
      "               Internet Services      0.035     0.018     0.024       385\n",
      "         Lending and Investments      0.018     0.005     0.008       186\n",
      "                   Manufacturing      0.071     0.011     0.019        89\n",
      "         Media and Entertainment      0.074     0.012     0.020       170\n",
      "Messaging and Telecommunications      0.000     0.000     0.000        39\n",
      "                          Mobile      0.000     0.000     0.000       212\n",
      "                 Music and Audio      0.000     0.000     0.000        20\n",
      "               Natural Resources      0.000     0.000     0.000        29\n",
      "          Navigation and Mapping      0.000     0.000     0.000        20\n",
      "                           Other      0.031     0.007     0.011       290\n",
      "                        Payments      0.000     0.000     0.000       131\n",
      "                       Platforms      0.000     0.000     0.000        24\n",
      "            Privacy and Security      0.000     0.000     0.000       113\n",
      "           Professional Services      0.019     0.007     0.010       150\n",
      "                     Real Estate      0.053     0.018     0.027       110\n",
      "             Sales and Marketing      0.000     0.000     0.000       157\n",
      "         Science and Engineering      0.081     0.081     0.081       405\n",
      "                        Software      0.143     0.582     0.229      1019\n",
      "                          Sports      0.000     0.000     0.000        54\n",
      "                  Sustainability      0.000     0.000     0.000        64\n",
      "                  Transportation      0.043     0.036     0.040       192\n",
      "              Travel and Tourism      0.000     0.000     0.000        48\n",
      "                           Video      0.000     0.000     0.000        49\n",
      "\n",
      "                        accuracy                          0.102      7726\n",
      "                       macro avg      0.022     0.026     0.019      7726\n",
      "                    weighted avg      0.049     0.102     0.054      7726\n",
      "\n",
      "\n",
      "ResNet-MLP — LOGO-LEVEL MEMBERSHIP ACCURACY\n",
      "\n",
      "ResNet-MLP — TRAIN membership accuracy:\n",
      "  6843/7954 = 0.8603\n",
      "\n",
      "ResNet-MLP — TEST membership accuracy:\n",
      "  789/1989 = 0.3967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8603218506411868, 0.39668174962292607)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "train_ds = EmbeddingDataset(X_train, y_train)\n",
    "test_ds  = EmbeddingDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=256, shuffle=False)\n",
    "\n",
    "\n",
    "class ResNetStyleHead(nn.Module):\n",
    "    \"\"\"\n",
    "    A small residual MLP head on top of 512-d ResNet embeddings:\n",
    "      x -> FC(512) -> ReLU -> FC(512) -> +x -> ReLU -> FC(num_classes)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim=512, num_classes=47):  # 47 if that's your class count\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc_out = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, in_dim]\n",
    "        residual = x\n",
    "        out = F.relu(self.fc1(x))\n",
    "        out = self.fc2(out)\n",
    "        out = F.relu(out + residual)  # residual connection\n",
    "        out = self.fc_out(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "num_classes = len(le.classes_)\n",
    "resnet_head = ResNetStyleHead(in_dim=X_train.shape[1], num_classes=num_classes).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(resnet_head.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def train_resnet_head_one_epoch():\n",
    "    resnet_head.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = resnet_head(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        total_correct += (preds == yb).sum().item()\n",
    "        total += xb.size(0)\n",
    "\n",
    "    return total_loss / total, total_correct / total\n",
    "\n",
    "\n",
    "def eval_resnet_head(loader):\n",
    "    resnet_head.eval()\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            logits = resnet_head(xb)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            total_correct += (preds == yb).sum().item()\n",
    "            total += xb.size(0)\n",
    "\n",
    "    acc = total_correct / total\n",
    "    return acc\n",
    "\n",
    "\n",
    "print(\"\\nTraining ResNet-style MLP head on embeddings...\")\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc_resnet = train_resnet_head_one_epoch()\n",
    "    test_acc_resnet = eval_resnet_head(test_loader)\n",
    "    print(f\"Epoch {epoch+1:2d} | Train loss: {train_loss:.4f} | \"\n",
    "          f\"Train acc: {train_acc_resnet:.4f} | Test acc: {test_acc_resnet:.4f}\")\n",
    "\n",
    "\n",
    "class ResNetHeadWrapper:\n",
    "    def __init__(self, net, device, batch_size=256):\n",
    "        self.net = net\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        X: numpy array of shape [N, D] (same as X_train / X_test)\n",
    "        returns: numpy array of predicted class indices [N]\n",
    "        \"\"\"\n",
    "        self.net.eval()\n",
    "        X_np = X.astype(np.float32)\n",
    "        preds_all = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(X_np), self.batch_size):\n",
    "                xb = torch.from_numpy(X_np[i:i + self.batch_size]).to(self.device)\n",
    "                logits = self.net(xb)\n",
    "                preds = logits.argmax(dim=1).cpu().numpy()\n",
    "                preds_all.append(preds)\n",
    "\n",
    "        return np.concatenate(preds_all)\n",
    "\n",
    "\n",
    "resnet_head_sklearn = ResNetHeadWrapper(resnet_head, device)\n",
    "\n",
    "evaluate_membership_accuracy(\n",
    "    model=resnet_head_sklearn,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    logo_train_split=logo_train_split,\n",
    "    logo_test_split=logo_test_split,\n",
    "    le=le,\n",
    "    df_features=df_features,\n",
    "    name=\"ResNet-MLP\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3e22cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

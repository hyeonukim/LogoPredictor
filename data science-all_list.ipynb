{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3179493e-6706-439f-84d4-752cbacf965d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUSINESS LOGO DOMAIN CLASSIFICATION\n",
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "Using device: cuda\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import os\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "import ast\n",
    "\n",
    "print(\"BUSINESS LOGO DOMAIN CLASSIFICATION\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b30a01",
   "metadata": {},
   "source": [
    "# Category Group List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42087470-cdfd-4041-b307-6ffe11fb9589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded 10000 samples\n",
      " Columns: ['uuid', 'name', 'type', 'permalink', 'cb_url', 'rank', 'created_at', 'updated_at', 'legal_name', 'roles', 'domain', 'homepage_url', 'region', 'city', 'address', 'postal_code', 'status', 'short_description', 'num_funding_rounds', 'total_funding_usd', 'total_funding', 'total_funding_currency_code', 'founded_on', 'last_funding_on', 'closed_on', 'employee_count', 'email', 'phone', 'facebook_url', 'linkedin_url', 'twitter_url', 'state_code', 'logo_url', 'country_code', 'category_groups_list', 'category_list', 'new_logo_url']\n",
      " Found 9998 logo files\n",
      "✓ Matched 9990 logos (99.9%)\n",
      " Logos with at least 1 category: 9990\n",
      "✓ Total unique categories (multi-label): 47\n",
      "✓ Total samples (logos with at least 1 matched file): 9990\n",
      "\n",
      "Category frequency distribution (based on individual categories):\n",
      "  Categories with 1 sample:      2861\n",
      "  Categories with 2-4 samples:   819\n",
      "  Categories with 5-9 samples:   200\n",
      "  Categories with 10-19 samples: 75\n",
      "  Categories with 20+ samples:   51\n",
      "\n",
      "Top 20 most common categories:\n",
      "  1. [5076] Software\n",
      "  2. [2378] Financial Services\n",
      "  3. [2301] Information Technology\n",
      "  4. [2043] Science and Engineering\n",
      "  5. [2007] Internet Services\n",
      "  6. [1893] Data and Analytics\n",
      "  7. [1720] Health Care\n",
      "  8. [1455] Hardware\n",
      "  9. [1373] Commerce and Shopping\n",
      " 10. [1373] Other\n",
      " 11. [1085] Artificial Intelligence\n",
      " 12. [1073] Mobile\n",
      " 13. [ 956] Lending and Investments\n",
      " 14. [ 903] Transportation\n",
      " 15. [ 863] Media and Entertainment\n",
      " 16. [ 810] Professional Services\n",
      " 17. [ 778] Sales and Marketing\n",
      " 18. [ 778] Biotechnology\n",
      " 19. [ 753] Apps\n",
      " 20. [ 688] Payments\n"
     ]
    }
   ],
   "source": [
    "csv_path = r\"C:\\BCIT\\data_science\\project\\LogoPredictor\\top10k_logos.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "logo_dir = r\"C:\\BCIT\\data_science\\project\\logo_images\"\n",
    "\n",
    "print(f\" Loaded {len(df)} samples\")\n",
    "print(f\" Columns: {df.columns.tolist()}\")\n",
    "\n",
    "# Get list of available logo files\n",
    "logo_files = os.listdir(logo_dir)\n",
    "logo_files_set = set(logo_files)\n",
    "print(f\" Found {len(logo_files)} logo files\")\n",
    "\n",
    "def clean_name(name):\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    name = str(name).lower().replace(' ', '_').replace('-', '_')\n",
    "    return ''.join(c for c in name if c.isalnum() or c == '_')\n",
    "\n",
    "df['clean_name'] = df['name'].apply(clean_name)\n",
    "\n",
    "\n",
    "matched_rows = []\n",
    "for logo_file in logo_files:\n",
    "    logo_name_raw = os.path.splitext(logo_file)[0]\n",
    "\n",
    "    # Many files may be like \"12345_company_name\", so drop leading ID part\n",
    "    if '_' in logo_name_raw:\n",
    "        logo_name = '_'.join(logo_name_raw.split('_', 1)[1:])\n",
    "    else:\n",
    "        logo_name = logo_name_raw\n",
    "    \n",
    "    logo_cleaned = clean_name(logo_name)\n",
    "    \n",
    "    # Find matching row in df\n",
    "    matches = df[df['clean_name'] == logo_cleaned]\n",
    "    if len(matches) > 0:\n",
    "        row = matches.iloc[0].copy()\n",
    "        row['logo_filename'] = logo_file\n",
    "        matched_rows.append(row)\n",
    "\n",
    "df_matched = pd.DataFrame(matched_rows)\n",
    "print(f\"✓ Matched {len(df_matched)} logos ({len(df_matched)/len(logo_files)*100:.1f}%)\")\n",
    "\n",
    "def parse_categories(x):\n",
    "    \"\"\"\n",
    "    Convert the raw category_groups_list string into a Python list.\n",
    "    Handles:\n",
    "      - \"['Software', 'AI']\"   (Python-list style)\n",
    "      - \"Software, AI\"        (comma-separated)\n",
    "      - NaNs                  (returns [])\n",
    "    \"\"\"\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    \n",
    "    x = str(x).strip()\n",
    "    \n",
    "    # Try to parse as Python list: \"['A', 'B']\"\n",
    "    if x.startswith('[') and x.endswith(']'):\n",
    "        try:\n",
    "            parsed = ast.literal_eval(x)\n",
    "            # Ensure list of strings\n",
    "            return [str(c).strip() for c in parsed]\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "    # Fallback: comma-separated string\n",
    "    return [c.strip() for c in x.split(',') if c.strip()]\n",
    "\n",
    "df_matched[\"parsed_categories\"] = df_matched[\"category_groups_list\"].apply(parse_categories)\n",
    "\n",
    "df_filtered = df_matched[df_matched[\"parsed_categories\"].map(len) > 0].copy()\n",
    "df_filtered = df_filtered.reset_index(drop=True)\n",
    "print(f\" Logos with at least 1 category: {len(df_filtered)}\")\n",
    "\n",
    "cat_counter = Counter()\n",
    "for cats in df_matched[\"parsed_categories\"]:\n",
    "    cat_counter.update(cats)\n",
    "\n",
    "# Convert to Series for convenience\n",
    "category_counts = pd.Series(cat_counter).sort_values(ascending=False)\n",
    "\n",
    "print(f\"✓ Total unique categories (multi-label): {len(category_counts)}\")\n",
    "print(f\"✓ Total samples (logos with at least 1 matched file): {len(df_matched)}\")\n",
    "\n",
    "# Distribution of category frequencies\n",
    "print(\"\\nCategory frequency distribution (based on individual categories):\")\n",
    "freq_values = df_matched['category_groups_list'].value_counts()\n",
    "print(f\"  Categories with 1 sample:      {(freq_values == 1).sum()}\")\n",
    "print(f\"  Categories with 2-4 samples:   {((freq_values >= 2) & (freq_values <= 4)).sum()}\")\n",
    "print(f\"  Categories with 5-9 samples:   {((freq_values >= 5) & (freq_values <= 9)).sum()}\")\n",
    "print(f\"  Categories with 10-19 samples: {((freq_values >= 10) & (freq_values < 20)).sum()}\")\n",
    "print(f\"  Categories with 20+ samples:   {(freq_values >= 20).sum()}\")\n",
    "\n",
    "print(\"\\nTop 20 most common categories:\")\n",
    "for i, (cat, count) in enumerate(category_counts.head(20).items(), 1):\n",
    "    short_cat = cat[:70] + \"...\" if len(cat) > 70 else cat\n",
    "    print(f\"{i:3d}. [{count:4d}] {short_cat}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "240508b3-4654-4781-896f-4e5b0f982ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ResNet18 features...\n",
      "  200/9990\n",
      "  400/9990\n",
      "  600/9990\n",
      "  800/9990\n",
      "  1000/9990\n",
      "  1200/9990\n",
      "  1400/9990\n",
      "  1600/9990\n",
      "  1800/9990\n",
      "  2000/9990\n",
      "  2200/9990\n",
      "  2400/9990\n",
      "  2600/9990\n",
      "  2800/9990\n",
      "  3000/9990\n",
      "  3200/9990\n",
      "  3400/9990\n",
      "  3600/9990\n",
      "  3800/9990\n",
      "  4000/9990\n",
      "  4200/9990\n",
      "  4400/9990\n",
      "  4600/9990\n",
      "  4800/9990\n",
      "  5000/9990\n",
      "  5200/9990\n",
      "  5400/9990\n",
      "  5600/9990\n",
      "  5800/9990\n",
      "  6000/9990\n",
      "  6200/9990\n",
      "  6400/9990\n",
      "  6600/9990\n",
      "  6800/9990\n",
      "  7000/9990\n",
      "  7200/9990\n",
      "  7400/9990\n",
      "  7600/9990\n",
      "  7800/9990\n",
      "  8000/9990\n",
      "  8200/9990\n",
      "  8400/9990\n",
      "  8600/9990\n",
      "  8800/9990\n",
      "  9000/9990\n",
      "  9200/9990\n",
      "  9400/9990\n",
      "  9600/9990\n",
      "  9800/9990\n",
      "\n",
      "Done. Extracted 9943 features (failed: 47)\n",
      " Feature matrix shape X: (9943, 512)\n",
      " df_features rows: 9943\n"
     ]
    }
   ],
   "source": [
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet = nn.Sequential(*list(resnet.children())[:-1])  # drop final FC layer\n",
    "resnet = resnet.to(device)\n",
    "resnet.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "features_list = []\n",
    "success_indices = []   # indices in df_filtered that succeeded\n",
    "failed = 0\n",
    "\n",
    "print(\"\\nExtracting ResNet18 features...\")\n",
    "with torch.no_grad():\n",
    "    for idx, row in df_filtered.iterrows():\n",
    "        logo_path = os.path.join(logo_dir, row[\"logo_filename\"])\n",
    "        try:\n",
    "            img = Image.open(logo_path).convert(\"RGB\")\n",
    "            img_tensor = transform(img).unsqueeze(0).to(device)  # [1,3,224,224]\n",
    "\n",
    "            # [1,512,1,1] -> [512]\n",
    "            feat = resnet(img_tensor).view(-1).cpu().numpy()\n",
    "            features_list.append(feat)\n",
    "            success_indices.append(idx)\n",
    "\n",
    "            if len(features_list) % 200 == 0:\n",
    "                print(f\"  {len(features_list)}/{len(df_filtered)}\")\n",
    "        except Exception:\n",
    "            failed += 1\n",
    "\n",
    "X = np.stack(features_list)   # [num_successful_logos, 512]\n",
    "df_features = df_filtered.loc[success_indices].reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nDone. Extracted {len(X)} features (failed: {failed})\")\n",
    "print(\" Feature matrix shape X:\", X.shape)\n",
    "print(\" df_features rows:\", len(df_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e34d516d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After exploding into (logo, category) pairs:\n",
      " X_expanded shape: (38012, 512)\n",
      " y length: 38012\n",
      " Example pairs:\n",
      "  logo_idx=0, category=Financial Services\n",
      "  logo_idx=0, category=Hardware\n",
      "  logo_idx=0, category=Internet Services\n",
      "  logo_idx=0, category=Lending and Investments\n",
      "  logo_idx=0, category=Mobile\n"
     ]
    }
   ],
   "source": [
    "tmp = df_features[[\"parsed_categories\"]].copy()\n",
    "tmp = tmp.explode(\"parsed_categories\")   # one row per (logo, category)\n",
    "tmp = tmp.rename(columns={\"parsed_categories\": \"category\"})\n",
    "tmp = tmp.reset_index().rename(columns={\"index\": \"logo_idx\"})\n",
    "# columns: ['logo_idx', 'category']\n",
    "# logo_idx now runs from 0 .. len(df_features)-1 and matches X\n",
    "\n",
    "logo_indices = tmp[\"logo_idx\"].values          # which row in X to use\n",
    "X_expanded = X[logo_indices]                   # [num_pairs, 512]\n",
    "y = tmp[\"category\"].values                     # [num_pairs]\n",
    "\n",
    "print(\"\\nAfter exploding into (logo, category) pairs:\")\n",
    "print(\" X_expanded shape:\", X_expanded.shape)\n",
    "print(\" y length:\", len(y))\n",
    "print(\" Example pairs:\")\n",
    "for i in range(5):\n",
    "    print(f\"  logo_idx={logo_indices[i]}, category={y[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30e0ce17-aaf6-4971-89c0-a7118986fe35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 47 categories retained (single-label).\n",
      "  Samples per category: min=80, max=5052, mean=808.8\n",
      "\n",
      "Unique logos (after feature extraction): 9943\n",
      "\n",
      "Train rows: 30286, Test rows: 7726\n",
      "\n",
      "Train label distribution (first 10 classes):\n",
      "[ 382  226  125  592  864  632  136 1085  371  460]\n",
      "Test label distribution (first 10 classes):\n",
      "[104  53  34 156 218 142  27 280  93 130]\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "print(f\"\\n {len(le.classes_)} categories retained (single-label).\")\n",
    "binc = np.bincount(y_encoded)\n",
    "print(f\"  Samples per category: min={np.min(binc)}, max={np.max(binc)}, mean={np.mean(binc):.1f}\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_expanded)\n",
    "\n",
    "# Split by logo, so each logo is only in train OR test\n",
    "unique_logos = np.unique(logo_indices)\n",
    "print(f\"\\nUnique logos (after feature extraction): {len(unique_logos)}\")\n",
    "\n",
    "logo_train_ids, logo_test_ids = train_test_split(\n",
    "    unique_logos,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_mask = np.isin(logo_indices, logo_train_ids)\n",
    "test_mask  = np.isin(logo_indices, logo_test_ids)\n",
    "\n",
    "X_train = X_scaled[train_mask]\n",
    "y_train = y_encoded[train_mask]\n",
    "logo_train_split = logo_indices[train_mask]\n",
    "\n",
    "X_test  = X_scaled[test_mask]\n",
    "y_test  = y_encoded[test_mask]\n",
    "logo_test_split = logo_indices[test_mask]\n",
    "\n",
    "print(f\"\\nTrain rows: {len(X_train)}, Test rows: {len(X_test)}\")\n",
    "\n",
    "print(\"\\nTrain label distribution (first 10 classes):\")\n",
    "print(np.bincount(y_train)[:10])\n",
    "print(\"Test label distribution (first 10 classes):\")\n",
    "print(np.bincount(y_test)[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85962fa0",
   "metadata": {},
   "source": [
    "# Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1442528a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "def evaluate_membership_accuracy(model, X_train, y_train, X_test, y_test,\n",
    "                                 logo_train_split, logo_test_split, le, df_features,\n",
    "                                 name=\"MODEL\"):\n",
    "    print(f\"\\n\\n=== {name} — EVALUATION ===\")\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred  = model.predict(X_test)\n",
    "\n",
    "    print(f\"\\n{name} — ROW-LEVEL METRICS (exploded (logo, category) samples)\")\n",
    "\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    test_acc  = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    prec_w, rec_w, f1_w, _ = precision_recall_fscore_support(\n",
    "        y_test, y_test_pred, average=\"weighted\", zero_division=0\n",
    "    )\n",
    "    prec_m, rec_m, f1_m, _ = precision_recall_fscore_support(\n",
    "        y_test, y_test_pred, average=\"macro\", zero_division=0\n",
    "    )\n",
    "\n",
    "    print(f\"Train accuracy: {train_acc:.4f}\")\n",
    "    print(f\"Test  accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    print(\"\\nTest precision/recall/F1 (weighted):\")\n",
    "    print(f\"  Precision_w: {prec_w:.4f}\")\n",
    "    print(f\"  Recall_w:    {rec_w:.4f}\")\n",
    "    print(f\"  F1_w:        {f1_w:.4f}\")\n",
    "\n",
    "    print(\"\\nTest precision/recall/F1 (macro):\")\n",
    "    print(f\"  Precision_m: {prec_m:.4f}\")\n",
    "    print(f\"  Recall_m:    {rec_m:.4f}\")\n",
    "    print(f\"  F1_m:        {f1_m:.4f}\")\n",
    "\n",
    "    classes_in_test = np.unique(y_test)\n",
    "    target_names = le.inverse_transform(classes_in_test)\n",
    "    print(f\"\\n{name} — CLASSIFICATION REPORT (row-level)\")\n",
    "    print(\n",
    "        classification_report(\n",
    "            y_test,\n",
    "            y_test_pred,\n",
    "            labels=classes_in_test,\n",
    "            target_names=target_names,\n",
    "            digits=3,\n",
    "            zero_division=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "    print(f\"\\n{name} — LOGO-LEVEL MEMBERSHIP ACCURACY\")\n",
    "\n",
    "    y_train_pred_labels = le.inverse_transform(y_train_pred)\n",
    "    train_unique_logos = np.unique(logo_train_split)\n",
    "    correct_train = 0\n",
    "\n",
    "    for logo_idx in train_unique_logos:\n",
    "        rows = np.where(logo_train_split == logo_idx)[0]\n",
    "        preds = y_train_pred_labels[rows]\n",
    "        true_cats = df_features.loc[logo_idx, \"parsed_categories\"]\n",
    "\n",
    "        if any(p in true_cats for p in preds):\n",
    "            correct_train += 1\n",
    "\n",
    "    train_membership_acc = correct_train / len(train_unique_logos)\n",
    "\n",
    "    y_test_pred_labels = le.inverse_transform(y_test_pred)\n",
    "    test_unique_logos = np.unique(logo_test_split)\n",
    "    correct_test = 0\n",
    "\n",
    "    for logo_idx in test_unique_logos:\n",
    "        rows = np.where(logo_test_split == logo_idx)[0]\n",
    "        preds = y_test_pred_labels[rows]\n",
    "        true_cats = df_features.loc[logo_idx, \"parsed_categories\"]\n",
    "\n",
    "        if any(p in true_cats for p in preds):\n",
    "            correct_test += 1\n",
    "\n",
    "    test_membership_acc = correct_test / len(test_unique_logos)\n",
    "\n",
    "    print(f\"\\n{name} — TRAIN membership accuracy:\")\n",
    "    print(f\"  {correct_train}/{len(train_unique_logos)} = {train_membership_acc:.4f}\")\n",
    "\n",
    "    print(f\"\\n{name} — TEST membership accuracy:\")\n",
    "    print(f\"  {correct_test}/{len(test_unique_logos)} = {test_membership_acc:.4f}\")\n",
    "\n",
    "    return train_membership_acc, test_membership_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b557de9e",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ce5d677-ae08-4abb-bf66-78ce3d7754ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training RandomForestClassifier...\n",
      "\n",
      "\n",
      "=== RandomForest — EVALUATION ===\n",
      "\n",
      "RandomForest — ROW-LEVEL METRICS (exploded (logo, category) samples)\n",
      "Train accuracy: 0.2584\n",
      "Test  accuracy: 0.0325\n",
      "\n",
      "Test precision/recall/F1 (weighted):\n",
      "  Precision_w: 0.0549\n",
      "  Recall_w:    0.0325\n",
      "  F1_w:        0.0260\n",
      "\n",
      "Test precision/recall/F1 (macro):\n",
      "  Precision_m: 0.0290\n",
      "  Recall_m:    0.0404\n",
      "  F1_m:        0.0224\n",
      "\n",
      "RandomForest — CLASSIFICATION REPORT (row-level)\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "         Administrative Services      0.016     0.048     0.024       104\n",
      "                     Advertising      0.000     0.000     0.000        53\n",
      "         Agriculture and Farming      0.033     0.176     0.056        34\n",
      "                            Apps      0.033     0.096     0.049       156\n",
      "         Artificial Intelligence      0.017     0.014     0.015       218\n",
      "                   Biotechnology      0.037     0.437     0.068       142\n",
      "            Clothing and Apparel      0.032     0.185     0.055        27\n",
      "           Commerce and Shopping      0.030     0.007     0.012       280\n",
      "         Community and Lifestyle      0.021     0.022     0.021        93\n",
      "            Consumer Electronics      0.000     0.000     0.000       130\n",
      "                  Consumer Goods      0.035     0.049     0.041        61\n",
      "          Content and Publishing      0.000     0.000     0.000        61\n",
      "              Data and Analytics      0.040     0.010     0.016       399\n",
      "                          Design      0.013     0.010     0.011        96\n",
      "                       Education      0.012     0.033     0.017        92\n",
      "                          Energy      0.022     0.017     0.019        59\n",
      "                          Events      0.000     0.000     0.000        24\n",
      "              Financial Services      0.081     0.039     0.052       466\n",
      "               Food and Beverage      0.034     0.090     0.050       100\n",
      "                          Gaming      0.012     0.059     0.020        34\n",
      "         Government and Military      0.000     0.000     0.000        25\n",
      "                        Hardware      0.032     0.003     0.006       304\n",
      "                     Health Care      0.043     0.043     0.043       323\n",
      "          Information Technology      0.051     0.014     0.022       489\n",
      "               Internet Services      0.071     0.018     0.029       385\n",
      "         Lending and Investments      0.040     0.081     0.053       186\n",
      "                   Manufacturing      0.017     0.011     0.013        89\n",
      "         Media and Entertainment      0.000     0.000     0.000       170\n",
      "Messaging and Telecommunications      0.018     0.051     0.027        39\n",
      "                          Mobile      0.032     0.019     0.024       212\n",
      "                 Music and Audio      0.000     0.000     0.000        20\n",
      "               Natural Resources      0.000     0.000     0.000        29\n",
      "          Navigation and Mapping      0.012     0.050     0.020        20\n",
      "                           Other      0.033     0.014     0.019       290\n",
      "                        Payments      0.019     0.038     0.025       131\n",
      "                       Platforms      0.000     0.000     0.000        24\n",
      "            Privacy and Security      0.018     0.053     0.027       113\n",
      "           Professional Services      0.007     0.007     0.007       150\n",
      "                     Real Estate      0.026     0.073     0.039       110\n",
      "             Sales and Marketing      0.039     0.013     0.019       157\n",
      "         Science and Engineering      0.082     0.020     0.032       405\n",
      "                        Software      0.163     0.015     0.027      1019\n",
      "                          Sports      0.011     0.019     0.014        54\n",
      "                  Sustainability      0.125     0.016     0.028        64\n",
      "                  Transportation      0.041     0.031     0.035       192\n",
      "              Travel and Tourism      0.012     0.021     0.015        48\n",
      "                           Video      0.000     0.000     0.000        49\n",
      "\n",
      "                        accuracy                          0.032      7726\n",
      "                       macro avg      0.029     0.040     0.022      7726\n",
      "                    weighted avg      0.055     0.032     0.026      7726\n",
      "\n",
      "\n",
      "RandomForest — LOGO-LEVEL MEMBERSHIP ACCURACY\n",
      "\n",
      "RandomForest — TRAIN membership accuracy:\n",
      "  7827/7954 = 0.9840\n",
      "\n",
      "RandomForest — TEST membership accuracy:\n",
      "  251/1989 = 0.1262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9840331908473724, 0.12619406737053795)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=25,\n",
    "    min_samples_split=8,\n",
    "    min_samples_leaf=3,\n",
    "    max_features='sqrt',\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining RandomForestClassifier...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "evaluate_membership_accuracy(\n",
    "    model=model,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    logo_train_split=logo_train_split,\n",
    "    logo_test_split=logo_test_split,\n",
    "    le=le,\n",
    "    df_features=df_features,\n",
    "    name=\"RandomForest\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dc3e90",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64b9c29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training LogisticRegression (OvR) on X_train...\n",
      "LogisticRegression training complete.\n",
      "\n",
      "\n",
      "=== LogisticRegression — EVALUATION ===\n",
      "\n",
      "LogisticRegression — ROW-LEVEL METRICS (exploded (logo, category) samples)\n",
      "Train accuracy: 0.0583\n",
      "Test  accuracy: 0.0157\n",
      "\n",
      "Test precision/recall/F1 (weighted):\n",
      "  Precision_w: 0.0493\n",
      "  Recall_w:    0.0157\n",
      "  F1_w:        0.0122\n",
      "\n",
      "Test precision/recall/F1 (macro):\n",
      "  Precision_m: 0.0239\n",
      "  Recall_m:    0.0315\n",
      "  F1_m:        0.0158\n",
      "\n",
      "LogisticRegression — CLASSIFICATION REPORT (row-level)\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "         Administrative Services      0.014     0.038     0.021       104\n",
      "                     Advertising      0.003     0.019     0.005        53\n",
      "         Agriculture and Farming      0.011     0.059     0.019        34\n",
      "                            Apps      0.029     0.019     0.023       156\n",
      "         Artificial Intelligence      0.046     0.018     0.026       218\n",
      "                   Biotechnology      0.074     0.120     0.091       142\n",
      "            Clothing and Apparel      0.018     0.185     0.033        27\n",
      "           Commerce and Shopping      0.037     0.004     0.007       280\n",
      "         Community and Lifestyle      0.017     0.054     0.026        93\n",
      "            Consumer Electronics      0.021     0.023     0.022       130\n",
      "                  Consumer Goods      0.015     0.066     0.024        61\n",
      "          Content and Publishing      0.006     0.033     0.010        61\n",
      "              Data and Analytics      0.000     0.000     0.000       399\n",
      "                          Design      0.009     0.021     0.013        96\n",
      "                       Education      0.008     0.022     0.011        92\n",
      "                          Energy      0.009     0.051     0.015        59\n",
      "                          Events      0.000     0.000     0.000        24\n",
      "              Financial Services      0.056     0.002     0.004       466\n",
      "               Food and Beverage      0.021     0.040     0.028       100\n",
      "                          Gaming      0.009     0.088     0.016        34\n",
      "         Government and Military      0.000     0.000     0.000        25\n",
      "                        Hardware      0.000     0.000     0.000       304\n",
      "                     Health Care      0.043     0.006     0.011       323\n",
      "          Information Technology      0.031     0.002     0.004       489\n",
      "               Internet Services      0.067     0.003     0.005       385\n",
      "         Lending and Investments      0.010     0.005     0.007       186\n",
      "                   Manufacturing      0.004     0.011     0.006        89\n",
      "         Media and Entertainment      0.030     0.006     0.010       170\n",
      "Messaging and Telecommunications      0.018     0.128     0.032        39\n",
      "                          Mobile      0.026     0.009     0.014       212\n",
      "                 Music and Audio      0.008     0.050     0.014        20\n",
      "               Natural Resources      0.006     0.034     0.010        29\n",
      "          Navigation and Mapping      0.000     0.000     0.000        20\n",
      "                           Other      0.000     0.000     0.000       290\n",
      "                        Payments      0.040     0.053     0.046       131\n",
      "                       Platforms      0.000     0.000     0.000        24\n",
      "            Privacy and Security      0.025     0.044     0.032       113\n",
      "           Professional Services      0.033     0.013     0.019       150\n",
      "                     Real Estate      0.026     0.055     0.035       110\n",
      "             Sales and Marketing      0.028     0.013     0.018       157\n",
      "         Science and Engineering      0.100     0.010     0.018       405\n",
      "                        Software      0.167     0.001     0.002      1019\n",
      "                          Sports      0.005     0.037     0.009        54\n",
      "                  Sustainability      0.014     0.062     0.022        64\n",
      "                  Transportation      0.031     0.016     0.021       192\n",
      "              Travel and Tourism      0.000     0.000     0.000        48\n",
      "                           Video      0.010     0.061     0.017        49\n",
      "\n",
      "                        accuracy                          0.016      7726\n",
      "                       macro avg      0.024     0.032     0.016      7726\n",
      "                    weighted avg      0.049     0.016     0.012      7726\n",
      "\n",
      "\n",
      "LogisticRegression — LOGO-LEVEL MEMBERSHIP ACCURACY\n",
      "\n",
      "LogisticRegression — TRAIN membership accuracy:\n",
      "  1767/7954 = 0.2222\n",
      "\n",
      "LogisticRegression — TEST membership accuracy:\n",
      "  121/1989 = 0.0608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2221523761629369, 0.06083459024635495)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(\n",
    "    multi_class=\"ovr\",\n",
    "    max_iter=2000,\n",
    "    C=1.0,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining LogisticRegression (OvR) on X_train...\")\n",
    "logreg.fit(X_train, y_train)\n",
    "print(\"LogisticRegression training complete.\")\n",
    "\n",
    "evaluate_membership_accuracy(\n",
    "    model=logreg,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    logo_train_split=logo_train_split,\n",
    "    logo_test_split=logo_test_split,\n",
    "    le=le,\n",
    "    df_features=df_features,\n",
    "    name=\"LogisticRegression\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186db7b2",
   "metadata": {},
   "source": [
    "# ResNet Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e792f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training ResNet-style MLP head on embeddings...\n",
      "Epoch  1 | Train loss: 3.4473 | Train acc: 0.1235 | Test acc: 0.1314\n",
      "Epoch  2 | Train loss: 3.3144 | Train acc: 0.1323 | Test acc: 0.1287\n",
      "Epoch  3 | Train loss: 3.2201 | Train acc: 0.1338 | Test acc: 0.1226\n",
      "Epoch  4 | Train loss: 3.1084 | Train acc: 0.1355 | Test acc: 0.1195\n",
      "Epoch  5 | Train loss: 2.9808 | Train acc: 0.1412 | Test acc: 0.1158\n",
      "Epoch  6 | Train loss: 2.8608 | Train acc: 0.1453 | Test acc: 0.1108\n",
      "Epoch  7 | Train loss: 2.7516 | Train acc: 0.1488 | Test acc: 0.1089\n",
      "Epoch  8 | Train loss: 2.6610 | Train acc: 0.1494 | Test acc: 0.1091\n",
      "Epoch  9 | Train loss: 2.5777 | Train acc: 0.1522 | Test acc: 0.1063\n",
      "Epoch 10 | Train loss: 2.5129 | Train acc: 0.1543 | Test acc: 0.1034\n",
      "\n",
      "\n",
      "=== ResNet-MLP — EVALUATION ===\n",
      "\n",
      "ResNet-MLP — ROW-LEVEL METRICS (exploded (logo, category) samples)\n",
      "Train accuracy: 0.2245\n",
      "Test  accuracy: 0.1034\n",
      "\n",
      "Test precision/recall/F1 (weighted):\n",
      "  Precision_w: 0.0644\n",
      "  Recall_w:    0.1034\n",
      "  F1_w:        0.0597\n",
      "\n",
      "Test precision/recall/F1 (macro):\n",
      "  Precision_m: 0.0358\n",
      "  Recall_m:    0.0289\n",
      "  F1_m:        0.0241\n",
      "\n",
      "ResNet-MLP — CLASSIFICATION REPORT (row-level)\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "         Administrative Services      0.000     0.000     0.000       104\n",
      "                     Advertising      0.000     0.000     0.000        53\n",
      "         Agriculture and Farming      0.000     0.000     0.000        34\n",
      "                            Apps      0.000     0.000     0.000       156\n",
      "         Artificial Intelligence      0.000     0.000     0.000       218\n",
      "                   Biotechnology      0.163     0.056     0.084       142\n",
      "            Clothing and Apparel      0.000     0.000     0.000        27\n",
      "           Commerce and Shopping      0.062     0.050     0.055       280\n",
      "         Community and Lifestyle      0.039     0.022     0.028        93\n",
      "            Consumer Electronics      0.000     0.000     0.000       130\n",
      "                  Consumer Goods      0.000     0.000     0.000        61\n",
      "          Content and Publishing      0.000     0.000     0.000        61\n",
      "              Data and Analytics      0.062     0.015     0.024       399\n",
      "                          Design      0.000     0.000     0.000        96\n",
      "                       Education      0.031     0.011     0.016        92\n",
      "                          Energy      0.048     0.017     0.025        59\n",
      "                          Events      0.000     0.000     0.000        24\n",
      "              Financial Services      0.071     0.086     0.078       466\n",
      "               Food and Beverage      0.012     0.010     0.011       100\n",
      "                          Gaming      0.059     0.029     0.039        34\n",
      "         Government and Military      0.000     0.000     0.000        25\n",
      "                        Hardware      0.076     0.020     0.031       304\n",
      "                     Health Care      0.084     0.127     0.101       323\n",
      "          Information Technology      0.080     0.027     0.040       489\n",
      "               Internet Services      0.043     0.029     0.034       385\n",
      "         Lending and Investments      0.125     0.005     0.010       186\n",
      "                   Manufacturing      0.000     0.000     0.000        89\n",
      "         Media and Entertainment      0.024     0.035     0.028       170\n",
      "Messaging and Telecommunications      0.000     0.000     0.000        39\n",
      "                          Mobile      0.059     0.024     0.034       212\n",
      "                 Music and Audio      0.000     0.000     0.000        20\n",
      "               Natural Resources      0.000     0.000     0.000        29\n",
      "          Navigation and Mapping      0.000     0.000     0.000        20\n",
      "                           Other      0.039     0.017     0.024       290\n",
      "                        Payments      0.000     0.000     0.000       131\n",
      "                       Platforms      0.000     0.000     0.000        24\n",
      "            Privacy and Security      0.100     0.009     0.016       113\n",
      "           Professional Services      0.143     0.020     0.035       150\n",
      "                     Real Estate      0.021     0.018     0.020       110\n",
      "             Sales and Marketing      0.031     0.032     0.031       157\n",
      "         Science and Engineering      0.086     0.067     0.075       405\n",
      "                        Software      0.140     0.581     0.226      1019\n",
      "                          Sports      0.000     0.000     0.000        54\n",
      "                  Sustainability      0.000     0.000     0.000        64\n",
      "                  Transportation      0.053     0.031     0.039       192\n",
      "              Travel and Tourism      0.030     0.021     0.025        48\n",
      "                           Video      0.000     0.000     0.000        49\n",
      "\n",
      "                        accuracy                          0.103      7726\n",
      "                       macro avg      0.036     0.029     0.024      7726\n",
      "                    weighted avg      0.064     0.103     0.060      7726\n",
      "\n",
      "\n",
      "ResNet-MLP — LOGO-LEVEL MEMBERSHIP ACCURACY\n",
      "\n",
      "ResNet-MLP — TRAIN membership accuracy:\n",
      "  6799/7954 = 0.8548\n",
      "\n",
      "ResNet-MLP — TEST membership accuracy:\n",
      "  799/1989 = 0.4017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8547900427457883, 0.4017094017094017)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "train_ds = EmbeddingDataset(X_train, y_train)\n",
    "test_ds  = EmbeddingDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=256, shuffle=False)\n",
    "\n",
    "\n",
    "class ResNetStyleHead(nn.Module):\n",
    "    \"\"\"\n",
    "    A small residual MLP head on top of 512-d ResNet embeddings:\n",
    "      x -> FC(512) -> ReLU -> FC(512) -> +x -> ReLU -> FC(num_classes)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim=512, num_classes=47):  # 47 if that's your class count\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc_out = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, in_dim]\n",
    "        residual = x\n",
    "        out = F.relu(self.fc1(x))\n",
    "        out = self.fc2(out)\n",
    "        out = F.relu(out + residual)  # residual connection\n",
    "        out = self.fc_out(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "num_classes = len(le.classes_)\n",
    "resnet_head = ResNetStyleHead(in_dim=X_train.shape[1], num_classes=num_classes).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(resnet_head.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def train_resnet_head_one_epoch():\n",
    "    resnet_head.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = resnet_head(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        total_correct += (preds == yb).sum().item()\n",
    "        total += xb.size(0)\n",
    "\n",
    "    return total_loss / total, total_correct / total\n",
    "\n",
    "\n",
    "def eval_resnet_head(loader):\n",
    "    resnet_head.eval()\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            logits = resnet_head(xb)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            total_correct += (preds == yb).sum().item()\n",
    "            total += xb.size(0)\n",
    "\n",
    "    acc = total_correct / total\n",
    "    return acc\n",
    "\n",
    "\n",
    "print(\"\\nTraining ResNet-style MLP head on embeddings...\")\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc_resnet = train_resnet_head_one_epoch()\n",
    "    test_acc_resnet = eval_resnet_head(test_loader)\n",
    "    print(f\"Epoch {epoch+1:2d} | Train loss: {train_loss:.4f} | \"\n",
    "          f\"Train acc: {train_acc_resnet:.4f} | Test acc: {test_acc_resnet:.4f}\")\n",
    "\n",
    "\n",
    "class ResNetHeadWrapper:\n",
    "    def __init__(self, net, device, batch_size=256):\n",
    "        self.net = net\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        X: numpy array of shape [N, D] (same as X_train / X_test)\n",
    "        returns: numpy array of predicted class indices [N]\n",
    "        \"\"\"\n",
    "        self.net.eval()\n",
    "        X_np = X.astype(np.float32)\n",
    "        preds_all = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(X_np), self.batch_size):\n",
    "                xb = torch.from_numpy(X_np[i:i + self.batch_size]).to(self.device)\n",
    "                logits = self.net(xb)\n",
    "                preds = logits.argmax(dim=1).cpu().numpy()\n",
    "                preds_all.append(preds)\n",
    "\n",
    "        return np.concatenate(preds_all)\n",
    "\n",
    "\n",
    "resnet_head_sklearn = ResNetHeadWrapper(resnet_head, device)\n",
    "\n",
    "evaluate_membership_accuracy(\n",
    "    model=resnet_head_sklearn,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    logo_train_split=logo_train_split,\n",
    "    logo_test_split=logo_test_split,\n",
    "    le=le,\n",
    "    df_features=df_features,\n",
    "    name=\"ResNet-MLP\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ad7c17",
   "metadata": {},
   "source": [
    "# Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a3e22cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TOP-10 COUNTRIES (by logo count) ===\n",
      "country_clean\n",
      "USA    6299\n",
      "GBR     616\n",
      "IND     608\n",
      "CAN     282\n",
      "DEU     231\n",
      "CHN     225\n",
      "ISR     202\n",
      "FRA     148\n",
      "SGP     146\n",
      "AUS      89\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Logos in top-10 countries: 8846\n"
     ]
    }
   ],
   "source": [
    "if \"country_clean\" not in df_features.columns:\n",
    "    if \"country\" in df_features.columns:\n",
    "        country_col = \"country\"\n",
    "    elif \"country_code\" in df_features.columns:\n",
    "        country_col = \"country_code\"\n",
    "    else:\n",
    "        raise ValueError(\"No country/country_code column in df_features. Check df_features.columns.\")\n",
    "\n",
    "    df_features[\"country_clean\"] = (\n",
    "        df_features[country_col]\n",
    "        .fillna(\"Unknown\")\n",
    "        .astype(str)\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "country_counts = df_features[\"country_clean\"].value_counts()\n",
    "top10_countries = country_counts.head(10).index.tolist()\n",
    "\n",
    "print(\"\\n=== TOP-10 COUNTRIES (by logo count) ===\")\n",
    "print(country_counts.head(10))\n",
    "\n",
    "mask_top10 = df_features[\"country_clean\"].isin(top10_countries)\n",
    "df_features_top = df_features[mask_top10].reset_index(drop=True)\n",
    "X_top = X[mask_top10]   # X is [num_logos, 512] from your ResNet\n",
    "\n",
    "print(f\"\\nLogos in top-10 countries: {len(df_features_top)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "726bbef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique countries in top-10 subset: 10\n",
      "Countries: ['AUS', 'CAN', 'CHN', 'DEU', 'FRA', 'GBR', 'IND', 'ISR', 'SGP', 'USA']\n",
      "\n",
      "=== COUNTRY TRAIN/TEST SPLIT (TOP-10) ===\n",
      "Train logos: 7076, Test logos: 1770\n"
     ]
    }
   ],
   "source": [
    "le_country = LabelEncoder()\n",
    "y_top = df_features_top[\"country_clean\"].values\n",
    "y_top_enc = le_country.fit_transform(y_top)\n",
    "\n",
    "print(f\"\\nUnique countries in top-10 subset: {len(le_country.classes_)}\")\n",
    "print(\"Countries:\", list(le_country.classes_))\n",
    "\n",
    "logo_ids_top = np.arange(len(df_features_top))\n",
    "\n",
    "logo_train_ids, logo_test_ids = train_test_split(\n",
    "    logo_ids_top,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_top_enc\n",
    ")\n",
    "\n",
    "train_mask_country = np.isin(logo_ids_top, logo_train_ids)\n",
    "test_mask_country  = np.isin(logo_ids_top, logo_test_ids)\n",
    "\n",
    "X_train_country = X_top[train_mask_country]\n",
    "X_test_country  = X_top[test_mask_country]\n",
    "y_train_country = y_top_enc[train_mask_country]\n",
    "y_test_country  = y_top_enc[test_mask_country]\n",
    "\n",
    "print(\"\\n=== COUNTRY TRAIN/TEST SPLIT (TOP-10) ===\")\n",
    "print(f\"Train logos: {len(X_train_country)}, Test logos: {len(X_test_country)}\")\n",
    "\n",
    "\n",
    "scaler_country = StandardScaler()\n",
    "X_train_country_scaled = scaler_country.fit_transform(X_train_country)\n",
    "X_test_country_scaled  = scaler_country.transform(X_test_country)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "785b4430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_country_classifier(model, X_train, y_train, X_test, y_test, le_country, name=\"MODEL\"):\n",
    "    print(f\"\\n\\n=== {name} — COUNTRY PREDICTION (TOP-10) ===\")\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred  = model.predict(X_test)\n",
    "\n",
    "    # Accuracy\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    test_acc  = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    # Precision / Recall / F1 (macro + weighted)\n",
    "    prec_w, rec_w, f1_w, _ = precision_recall_fscore_support(\n",
    "        y_test, y_test_pred, average=\"weighted\", zero_division=0\n",
    "    )\n",
    "    prec_m, rec_m, f1_m, _ = precision_recall_fscore_support(\n",
    "        y_test, y_test_pred, average=\"macro\", zero_division=0\n",
    "    )\n",
    "\n",
    "    print(f\"Train accuracy: {train_acc:.4f}\")\n",
    "    print(f\"Test  accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    print(\"\\nTest precision/recall/F1 (weighted):\")\n",
    "    print(f\"  Precision_w: {prec_w:.4f}\")\n",
    "    print(f\"  Recall_w:    {rec_w:.4f}\")\n",
    "    print(f\"  F1_w:        {f1_w:.4f}\")\n",
    "\n",
    "    print(\"\\nTest precision/recall/F1 (macro):\")\n",
    "    print(f\"  Precision_m: {prec_m:.4f}\")\n",
    "    print(f\"  Recall_m:    {rec_m:.4f}\")\n",
    "    print(f\"  F1_m:        {f1_m:.4f}\")\n",
    "\n",
    "    # Classification report\n",
    "    classes_in_test = np.unique(y_test)\n",
    "    target_names = le_country.inverse_transform(classes_in_test)\n",
    "\n",
    "    print(f\"\\n{name} — CLASSIFICATION REPORT (per logo, country TOP-10)\")\n",
    "    print(\n",
    "        classification_report(\n",
    "            y_test,\n",
    "            y_test_pred,\n",
    "            labels=classes_in_test,\n",
    "            target_names=target_names,\n",
    "            digits=3,\n",
    "            zero_division=0\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5471b8f5",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a78f3a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training RandomForest for TOP-10 COUNTRY prediction...\n",
      "RandomForest (top-10 country) training complete.\n",
      "\n",
      "\n",
      "=== RandomForest-Country-Top10 — COUNTRY PREDICTION (TOP-10) ===\n",
      "Train accuracy: 1.0000\n",
      "Test  accuracy: 0.7124\n",
      "\n",
      "Test precision/recall/F1 (weighted):\n",
      "  Precision_w: 0.5325\n",
      "  Recall_w:    0.7124\n",
      "  F1_w:        0.5933\n",
      "\n",
      "Test precision/recall/F1 (macro):\n",
      "  Precision_m: 0.1712\n",
      "  Recall_m:    0.1022\n",
      "  F1_m:        0.0875\n",
      "\n",
      "RandomForest-Country-Top10 — CLASSIFICATION REPORT (per logo, country TOP-10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AUS      0.000     0.000     0.000        18\n",
      "         CAN      0.000     0.000     0.000        57\n",
      "         CHN      1.000     0.022     0.043        45\n",
      "         DEU      0.000     0.000     0.000        46\n",
      "         FRA      0.000     0.000     0.000        30\n",
      "         GBR      0.000     0.000     0.000       123\n",
      "         IND      0.000     0.000     0.000       122\n",
      "         ISR      0.000     0.000     0.000        40\n",
      "         SGP      0.000     0.000     0.000        29\n",
      "         USA      0.712     1.000     0.832      1260\n",
      "\n",
      "    accuracy                          0.712      1770\n",
      "   macro avg      0.171     0.102     0.088      1770\n",
      "weighted avg      0.532     0.712     0.593      1770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_country = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=25,\n",
    "    min_samples_split=8,\n",
    "    min_samples_leaf=3,\n",
    "    max_features='sqrt',\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining RandomForest for TOP-10 COUNTRY prediction...\")\n",
    "rf_country.fit(X_train_country_scaled, y_train_country)\n",
    "print(\"RandomForest (top-10 country) training complete.\")\n",
    "\n",
    "evaluate_country_classifier(\n",
    "    model=rf_country,\n",
    "    X_train=X_train_country_scaled,\n",
    "    y_train=y_train_country,\n",
    "    X_test=X_test_country_scaled,\n",
    "    y_test=y_test_country,\n",
    "    le_country=le_country,\n",
    "    name=\"RandomForest-Country-Top10\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc380b4",
   "metadata": {},
   "source": [
    "# LogRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d70f3fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training LogisticRegression for TOP-10 COUNTRY prediction...\n",
      "LogisticRegression (top-10 country) training complete.\n",
      "\n",
      "\n",
      "=== LogReg-Country-Top10 — COUNTRY PREDICTION (TOP-10) ===\n",
      "Train accuracy: 0.4484\n",
      "Test  accuracy: 0.2407\n",
      "\n",
      "Test precision/recall/F1 (weighted):\n",
      "  Precision_w: 0.5372\n",
      "  Recall_w:    0.2407\n",
      "  F1_w:        0.3124\n",
      "\n",
      "Test precision/recall/F1 (macro):\n",
      "  Precision_m: 0.1178\n",
      "  Recall_m:    0.1405\n",
      "  F1_m:        0.1037\n",
      "\n",
      "LogReg-Country-Top10 — CLASSIFICATION REPORT (per logo, country TOP-10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AUS      0.021     0.056     0.030        18\n",
      "         CAN      0.038     0.123     0.059        57\n",
      "         CHN      0.076     0.178     0.107        45\n",
      "         DEU      0.028     0.109     0.045        46\n",
      "         FRA      0.026     0.067     0.037        30\n",
      "         GBR      0.088     0.154     0.112       123\n",
      "         IND      0.104     0.213     0.139       122\n",
      "         ISR      0.035     0.125     0.054        40\n",
      "         SGP      0.034     0.103     0.051        29\n",
      "         USA      0.728     0.278     0.402      1260\n",
      "\n",
      "    accuracy                          0.241      1770\n",
      "   macro avg      0.118     0.141     0.104      1770\n",
      "weighted avg      0.537     0.241     0.312      1770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_country = LogisticRegression(\n",
    "    multi_class=\"ovr\",\n",
    "    max_iter=2000,\n",
    "    C=1.0,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining LogisticRegression for TOP-10 COUNTRY prediction...\")\n",
    "logreg_country.fit(X_train_country_scaled, y_train_country)\n",
    "print(\"LogisticRegression (top-10 country) training complete.\")\n",
    "\n",
    "evaluate_country_classifier(\n",
    "    model=logreg_country,\n",
    "    X_train=X_train_country_scaled,\n",
    "    y_train=y_train_country,\n",
    "    X_test=X_test_country_scaled,\n",
    "    y_test=y_test_country,\n",
    "    le_country=le_country,\n",
    "    name=\"LogReg-Country-Top10\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e24d559",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4a36dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training ResNet-style MLP head for TOP-10 COUNTRY prediction...\n",
      "Epoch  1 | Train loss: 1.2908 | Train acc: 0.6967 | Test acc: 0.7107\n",
      "Epoch  2 | Train loss: 1.1082 | Train acc: 0.7118 | Test acc: 0.7136\n",
      "Epoch  3 | Train loss: 1.0272 | Train acc: 0.7154 | Test acc: 0.7068\n",
      "Epoch  4 | Train loss: 0.9241 | Train acc: 0.7302 | Test acc: 0.6960\n",
      "Epoch  5 | Train loss: 0.8145 | Train acc: 0.7545 | Test acc: 0.6870\n",
      "Epoch  6 | Train loss: 0.6841 | Train acc: 0.7930 | Test acc: 0.6520\n",
      "Epoch  7 | Train loss: 0.5816 | Train acc: 0.8219 | Test acc: 0.6661\n",
      "Epoch  8 | Train loss: 0.4932 | Train acc: 0.8508 | Test acc: 0.6571\n",
      "Epoch  9 | Train loss: 0.4029 | Train acc: 0.8773 | Test acc: 0.6802\n",
      "Epoch 10 | Train loss: 0.3449 | Train acc: 0.8997 | Test acc: 0.6559\n",
      "\n",
      "\n",
      "=== ResNet-MLP-Country-Top10 — COUNTRY PREDICTION (TOP-10) ===\n",
      "Train accuracy: 0.9224\n",
      "Test  accuracy: 0.6559\n",
      "\n",
      "Test precision/recall/F1 (weighted):\n",
      "  Precision_w: 0.5236\n",
      "  Recall_w:    0.6559\n",
      "  F1_w:        0.5787\n",
      "\n",
      "Test precision/recall/F1 (macro):\n",
      "  Precision_m: 0.1091\n",
      "  Recall_m:    0.1116\n",
      "  F1_m:        0.1054\n",
      "\n",
      "ResNet-MLP-Country-Top10 — CLASSIFICATION REPORT (per logo, country TOP-10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AUS      0.000     0.000     0.000        18\n",
      "         CAN      0.000     0.000     0.000        57\n",
      "         CHN      0.212     0.156     0.179        45\n",
      "         DEU      0.000     0.000     0.000        46\n",
      "         FRA      0.000     0.000     0.000        30\n",
      "         GBR      0.095     0.033     0.048       123\n",
      "         IND      0.071     0.016     0.027       122\n",
      "         ISR      0.000     0.000     0.000        40\n",
      "         SGP      0.000     0.000     0.000        29\n",
      "         USA      0.712     0.911     0.799      1260\n",
      "\n",
      "    accuracy                          0.656      1770\n",
      "   macro avg      0.109     0.112     0.105      1770\n",
      "weighted avg      0.524     0.656     0.579      1770\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class CountryEmbeddingDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        # X should be numpy: [N, D]\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "train_ds_country = CountryEmbeddingDataset(X_train_country_scaled, y_train_country)\n",
    "test_ds_country  = CountryEmbeddingDataset(X_test_country_scaled,  y_test_country)\n",
    "\n",
    "train_loader_country = DataLoader(train_ds_country, batch_size=128, shuffle=True)\n",
    "test_loader_country  = DataLoader(test_ds_country,  batch_size=256, shuffle=False)\n",
    "\n",
    "\n",
    "class ResNetStyleHeadCountry(nn.Module):\n",
    "    \"\"\"\n",
    "    Residual MLP head on top of 512-d ResNet embeddings for country classification:\n",
    "      x -> FC(512) -> ReLU -> FC(512) -> +x -> ReLU -> FC(num_classes)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim=512, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc_out = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = F.relu(self.fc1(x))\n",
    "        out = self.fc2(out)\n",
    "        out = F.relu(out + residual)   # residual connection\n",
    "        out = self.fc_out(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "num_country_classes = len(le_country.classes_)\n",
    "resnet_country_head = ResNetStyleHeadCountry(\n",
    "    in_dim=X_train_country_scaled.shape[1],\n",
    "    num_classes=num_country_classes\n",
    ").to(device)\n",
    "\n",
    "optimizer_country = torch.optim.Adam(resnet_country_head.parameters(), lr=1e-3)\n",
    "criterion_country = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def train_country_head_one_epoch():\n",
    "    resnet_country_head.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for xb, yb in train_loader_country:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        optimizer_country.zero_grad()\n",
    "        logits = resnet_country_head(xb)\n",
    "        loss = criterion_country(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer_country.step()\n",
    "\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        total_correct += (preds == yb).sum().item()\n",
    "        total += xb.size(0)\n",
    "\n",
    "    return total_loss / total, total_correct / total\n",
    "\n",
    "\n",
    "def eval_country_head(loader):\n",
    "    resnet_country_head.eval()\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            logits = resnet_country_head(xb)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            total_correct += (preds == yb).sum().item()\n",
    "            total += xb.size(0)\n",
    "\n",
    "    acc = total_correct / total\n",
    "    return acc\n",
    "\n",
    "\n",
    "print(\"\\nTraining ResNet-style MLP head for TOP-10 COUNTRY prediction...\")\n",
    "num_epochs_country = 10\n",
    "for epoch in range(num_epochs_country):\n",
    "    train_loss_c, train_acc_c = train_country_head_one_epoch()\n",
    "    test_acc_c = eval_country_head(test_loader_country)\n",
    "    print(f\"Epoch {epoch+1:2d} | Train loss: {train_loss_c:.4f} | \"\n",
    "          f\"Train acc: {train_acc_c:.4f} | Test acc: {test_acc_c:.4f}\")\n",
    "\n",
    "\n",
    "# sklearn-style wrapper so we can reuse evaluate_country_classifier\n",
    "class ResNetCountryWrapper:\n",
    "    def __init__(self, net, device, batch_size=256):\n",
    "        self.net = net\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        X: numpy array [N, D] (same scaled feature space as X_train_country_scaled)\n",
    "        returns: numpy array of predicted class indices [N]\n",
    "        \"\"\"\n",
    "        self.net.eval()\n",
    "        X_np = X.astype(np.float32)\n",
    "        preds_all = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(X_np), self.batch_size):\n",
    "                xb = torch.from_numpy(X_np[i:i + self.batch_size]).to(self.device)\n",
    "                logits = self.net(xb)\n",
    "                preds = logits.argmax(dim=1).cpu().numpy()\n",
    "                preds_all.append(preds)\n",
    "\n",
    "        return np.concatenate(preds_all)\n",
    "\n",
    "\n",
    "resnet_country_model = ResNetCountryWrapper(resnet_country_head, device)\n",
    "\n",
    "evaluate_country_classifier(\n",
    "    model=resnet_country_model,\n",
    "    X_train=X_train_country_scaled,\n",
    "    y_train=y_train_country,\n",
    "    X_test=X_test_country_scaled,\n",
    "    y_test=y_test_country,\n",
    "    le_country=le_country,\n",
    "    name=\"ResNet-MLP-Country-Top10\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64826297",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

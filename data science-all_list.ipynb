{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3179493e-6706-439f-84d4-752cbacf965d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUSINESS LOGO DOMAIN CLASSIFICATION\n",
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "Using device: cuda\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import os\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "import ast\n",
    "\n",
    "print(\"BUSINESS LOGO DOMAIN CLASSIFICATION\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42087470-cdfd-4041-b307-6ffe11fb9589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded 10000 samples\n",
      " Columns: ['uuid', 'name', 'type', 'permalink', 'cb_url', 'rank', 'created_at', 'updated_at', 'legal_name', 'roles', 'domain', 'homepage_url', 'region', 'city', 'address', 'postal_code', 'status', 'short_description', 'num_funding_rounds', 'total_funding_usd', 'total_funding', 'total_funding_currency_code', 'founded_on', 'last_funding_on', 'closed_on', 'employee_count', 'email', 'phone', 'facebook_url', 'linkedin_url', 'twitter_url', 'state_code', 'logo_url', 'country_code', 'category_groups_list', 'category_list', 'new_logo_url']\n",
      " Found 9998 logo files\n",
      "✓ Matched 9990 logos (99.9%)\n",
      " Logos with at least 1 category: 9990\n",
      "✓ Total unique categories (multi-label): 47\n",
      "✓ Total samples (logos with at least 1 matched file): 9990\n",
      "\n",
      "Category frequency distribution (based on individual categories):\n",
      "  Categories with 1 sample:      2861\n",
      "  Categories with 2-4 samples:   819\n",
      "  Categories with 5-9 samples:   200\n",
      "  Categories with 10-19 samples: 75\n",
      "  Categories with 20+ samples:   51\n",
      "\n",
      "Top 20 most common categories:\n",
      "  1. [5076] Software\n",
      "  2. [2378] Financial Services\n",
      "  3. [2301] Information Technology\n",
      "  4. [2043] Science and Engineering\n",
      "  5. [2007] Internet Services\n",
      "  6. [1893] Data and Analytics\n",
      "  7. [1720] Health Care\n",
      "  8. [1455] Hardware\n",
      "  9. [1373] Commerce and Shopping\n",
      " 10. [1373] Other\n",
      " 11. [1085] Artificial Intelligence\n",
      " 12. [1073] Mobile\n",
      " 13. [ 956] Lending and Investments\n",
      " 14. [ 903] Transportation\n",
      " 15. [ 863] Media and Entertainment\n",
      " 16. [ 810] Professional Services\n",
      " 17. [ 778] Sales and Marketing\n",
      " 18. [ 778] Biotechnology\n",
      " 19. [ 753] Apps\n",
      " 20. [ 688] Payments\n"
     ]
    }
   ],
   "source": [
    "csv_path = r\"C:\\BCIT\\data_science\\project\\LogoPredictor\\top10k_logos.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "logo_dir = r\"C:\\BCIT\\data_science\\project\\logo_images\"\n",
    "\n",
    "print(f\" Loaded {len(df)} samples\")\n",
    "print(f\" Columns: {df.columns.tolist()}\")\n",
    "\n",
    "# Get list of available logo files\n",
    "logo_files = os.listdir(logo_dir)\n",
    "logo_files_set = set(logo_files)\n",
    "print(f\" Found {len(logo_files)} logo files\")\n",
    "\n",
    "def clean_name(name):\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    name = str(name).lower().replace(' ', '_').replace('-', '_')\n",
    "    return ''.join(c for c in name if c.isalnum() or c == '_')\n",
    "\n",
    "df['clean_name'] = df['name'].apply(clean_name)\n",
    "\n",
    "\n",
    "matched_rows = []\n",
    "for logo_file in logo_files:\n",
    "    logo_name_raw = os.path.splitext(logo_file)[0]\n",
    "\n",
    "    # Many files may be like \"12345_company_name\", so drop leading ID part\n",
    "    if '_' in logo_name_raw:\n",
    "        logo_name = '_'.join(logo_name_raw.split('_', 1)[1:])\n",
    "    else:\n",
    "        logo_name = logo_name_raw\n",
    "    \n",
    "    logo_cleaned = clean_name(logo_name)\n",
    "    \n",
    "    # Find matching row in df\n",
    "    matches = df[df['clean_name'] == logo_cleaned]\n",
    "    if len(matches) > 0:\n",
    "        row = matches.iloc[0].copy()\n",
    "        row['logo_filename'] = logo_file\n",
    "        matched_rows.append(row)\n",
    "\n",
    "df_matched = pd.DataFrame(matched_rows)\n",
    "print(f\"✓ Matched {len(df_matched)} logos ({len(df_matched)/len(logo_files)*100:.1f}%)\")\n",
    "\n",
    "def parse_categories(x):\n",
    "    \"\"\"\n",
    "    Convert the raw category_groups_list string into a Python list.\n",
    "    Handles:\n",
    "      - \"['Software', 'AI']\"   (Python-list style)\n",
    "      - \"Software, AI\"        (comma-separated)\n",
    "      - NaNs                  (returns [])\n",
    "    \"\"\"\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    \n",
    "    x = str(x).strip()\n",
    "    \n",
    "    # Try to parse as Python list: \"['A', 'B']\"\n",
    "    if x.startswith('[') and x.endswith(']'):\n",
    "        try:\n",
    "            parsed = ast.literal_eval(x)\n",
    "            # Ensure list of strings\n",
    "            return [str(c).strip() for c in parsed]\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "    # Fallback: comma-separated string\n",
    "    return [c.strip() for c in x.split(',') if c.strip()]\n",
    "\n",
    "df_matched[\"parsed_categories\"] = df_matched[\"category_groups_list\"].apply(parse_categories)\n",
    "\n",
    "df_filtered = df_matched[df_matched[\"parsed_categories\"].map(len) > 0].copy()\n",
    "df_filtered = df_filtered.reset_index(drop=True)\n",
    "print(f\" Logos with at least 1 category: {len(df_filtered)}\")\n",
    "\n",
    "cat_counter = Counter()\n",
    "for cats in df_matched[\"parsed_categories\"]:\n",
    "    cat_counter.update(cats)\n",
    "\n",
    "# Convert to Series for convenience\n",
    "category_counts = pd.Series(cat_counter).sort_values(ascending=False)\n",
    "\n",
    "print(f\"✓ Total unique categories (multi-label): {len(category_counts)}\")\n",
    "print(f\"✓ Total samples (logos with at least 1 matched file): {len(df_matched)}\")\n",
    "\n",
    "# Distribution of category frequencies\n",
    "print(\"\\nCategory frequency distribution (based on individual categories):\")\n",
    "freq_values = df_matched['category_groups_list'].value_counts()\n",
    "print(f\"  Categories with 1 sample:      {(freq_values == 1).sum()}\")\n",
    "print(f\"  Categories with 2-4 samples:   {((freq_values >= 2) & (freq_values <= 4)).sum()}\")\n",
    "print(f\"  Categories with 5-9 samples:   {((freq_values >= 5) & (freq_values <= 9)).sum()}\")\n",
    "print(f\"  Categories with 10-19 samples: {((freq_values >= 10) & (freq_values < 20)).sum()}\")\n",
    "print(f\"  Categories with 20+ samples:   {(freq_values >= 20).sum()}\")\n",
    "\n",
    "print(\"\\nTop 20 most common categories:\")\n",
    "for i, (cat, count) in enumerate(category_counts.head(20).items(), 1):\n",
    "    short_cat = cat[:70] + \"...\" if len(cat) > 70 else cat\n",
    "    print(f\"{i:3d}. [{count:4d}] {short_cat}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "240508b3-4654-4781-896f-4e5b0f982ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ResNet18 features...\n",
      "  200/9990\n",
      "  400/9990\n",
      "  600/9990\n",
      "  800/9990\n",
      "  1000/9990\n",
      "  1200/9990\n",
      "  1400/9990\n",
      "  1600/9990\n",
      "  1800/9990\n",
      "  2000/9990\n",
      "  2200/9990\n",
      "  2400/9990\n",
      "  2600/9990\n",
      "  2800/9990\n",
      "  3000/9990\n",
      "  3200/9990\n",
      "  3400/9990\n",
      "  3600/9990\n",
      "  3800/9990\n",
      "  4000/9990\n",
      "  4200/9990\n",
      "  4400/9990\n",
      "  4600/9990\n",
      "  4800/9990\n",
      "  5000/9990\n",
      "  5200/9990\n",
      "  5400/9990\n",
      "  5600/9990\n",
      "  5800/9990\n",
      "  6000/9990\n",
      "  6200/9990\n",
      "  6400/9990\n",
      "  6600/9990\n",
      "  6800/9990\n",
      "  7000/9990\n",
      "  7200/9990\n",
      "  7400/9990\n",
      "  7600/9990\n",
      "  7800/9990\n",
      "  8000/9990\n",
      "  8200/9990\n",
      "  8400/9990\n",
      "  8600/9990\n",
      "  8800/9990\n",
      "  9000/9990\n",
      "  9200/9990\n",
      "  9400/9990\n",
      "  9600/9990\n",
      "  9800/9990\n",
      "\n",
      "Done. Extracted 9943 features (failed: 47)\n",
      " Feature matrix shape X: (9943, 512)\n",
      " df_features rows: 9943\n"
     ]
    }
   ],
   "source": [
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet = nn.Sequential(*list(resnet.children())[:-1])  # drop final FC layer\n",
    "resnet = resnet.to(device)\n",
    "resnet.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "features_list = []\n",
    "success_indices = []   # indices in df_filtered that succeeded\n",
    "failed = 0\n",
    "\n",
    "print(\"\\nExtracting ResNet18 features...\")\n",
    "with torch.no_grad():\n",
    "    for idx, row in df_filtered.iterrows():\n",
    "        logo_path = os.path.join(logo_dir, row[\"logo_filename\"])\n",
    "        try:\n",
    "            img = Image.open(logo_path).convert(\"RGB\")\n",
    "            img_tensor = transform(img).unsqueeze(0).to(device)  # [1,3,224,224]\n",
    "\n",
    "            # [1,512,1,1] -> [512]\n",
    "            feat = resnet(img_tensor).view(-1).cpu().numpy()\n",
    "            features_list.append(feat)\n",
    "            success_indices.append(idx)\n",
    "\n",
    "            if len(features_list) % 200 == 0:\n",
    "                print(f\"  {len(features_list)}/{len(df_filtered)}\")\n",
    "        except Exception:\n",
    "            failed += 1\n",
    "\n",
    "X = np.stack(features_list)   # [num_successful_logos, 512]\n",
    "df_features = df_filtered.loc[success_indices].reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nDone. Extracted {len(X)} features (failed: {failed})\")\n",
    "print(\" Feature matrix shape X:\", X.shape)\n",
    "print(\" df_features rows:\", len(df_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e34d516d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After exploding into (logo, category) pairs:\n",
      " X_expanded shape: (38012, 512)\n",
      " y length: 38012\n",
      " Example pairs:\n",
      "  logo_idx=0, category=Financial Services\n",
      "  logo_idx=0, category=Hardware\n",
      "  logo_idx=0, category=Internet Services\n",
      "  logo_idx=0, category=Lending and Investments\n",
      "  logo_idx=0, category=Mobile\n"
     ]
    }
   ],
   "source": [
    "tmp = df_features[[\"parsed_categories\"]].copy()\n",
    "tmp = tmp.explode(\"parsed_categories\")   # one row per (logo, category)\n",
    "tmp = tmp.rename(columns={\"parsed_categories\": \"category\"})\n",
    "tmp = tmp.reset_index().rename(columns={\"index\": \"logo_idx\"})\n",
    "# columns: ['logo_idx', 'category']\n",
    "# logo_idx now runs from 0 .. len(df_features)-1 and matches X\n",
    "\n",
    "logo_indices = tmp[\"logo_idx\"].values          # which row in X to use\n",
    "X_expanded = X[logo_indices]                   # [num_pairs, 512]\n",
    "y = tmp[\"category\"].values                     # [num_pairs]\n",
    "\n",
    "print(\"\\nAfter exploding into (logo, category) pairs:\")\n",
    "print(\" X_expanded shape:\", X_expanded.shape)\n",
    "print(\" y length:\", len(y))\n",
    "print(\" Example pairs:\")\n",
    "for i in range(5):\n",
    "    print(f\"  logo_idx={logo_indices[i]}, category={y[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30e0ce17-aaf6-4971-89c0-a7118986fe35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 47 categories retained (single-label).\n",
      "  Samples per category: min=80, max=5052, mean=808.8\n",
      "\n",
      "Unique logos (after feature extraction): 9943\n",
      "\n",
      "Train rows: 30286, Test rows: 7726\n",
      "\n",
      "Train label distribution (first 10 classes):\n",
      "[ 382  226  125  592  864  632  136 1085  371  460]\n",
      "Test label distribution (first 10 classes):\n",
      "[104  53  34 156 218 142  27 280  93 130]\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "print(f\"\\n {len(le.classes_)} categories retained (single-label).\")\n",
    "binc = np.bincount(y_encoded)\n",
    "print(f\"  Samples per category: min={np.min(binc)}, max={np.max(binc)}, mean={np.mean(binc):.1f}\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_expanded)\n",
    "\n",
    "# Split by logo, so each logo is only in train OR test\n",
    "unique_logos = np.unique(logo_indices)\n",
    "print(f\"\\nUnique logos (after feature extraction): {len(unique_logos)}\")\n",
    "\n",
    "logo_train_ids, logo_test_ids = train_test_split(\n",
    "    unique_logos,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_mask = np.isin(logo_indices, logo_train_ids)\n",
    "test_mask  = np.isin(logo_indices, logo_test_ids)\n",
    "\n",
    "X_train = X_scaled[train_mask]\n",
    "y_train = y_encoded[train_mask]\n",
    "logo_train_split = logo_indices[train_mask]\n",
    "\n",
    "X_test  = X_scaled[test_mask]\n",
    "y_test  = y_encoded[test_mask]\n",
    "logo_test_split = logo_indices[test_mask]\n",
    "\n",
    "print(f\"\\nTrain rows: {len(X_train)}, Test rows: {len(X_test)}\")\n",
    "\n",
    "print(\"\\nTrain label distribution (first 10 classes):\")\n",
    "print(np.bincount(y_train)[:10])\n",
    "print(\"Test label distribution (first 10 classes):\")\n",
    "print(np.bincount(y_test)[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ce5d677-ae08-4abb-bf66-78ce3d7754ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training RandomForestClassifier...\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=25,\n",
    "    min_samples_split=8,\n",
    "    min_samples_leaf=3,\n",
    "    max_features='sqrt',\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining RandomForestClassifier...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2711ab6-2ce4-4ad9-a98f-e6b93660f326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RESULTS (Standard single-label accuracy on (logo, category) pairs)\n",
      "================================================================================\n",
      "Training Accuracy: 0.2584 (25.84%)\n",
      "Testing Accuracy:  0.0325 (3.25%)\n",
      "F1-Score (weighted): 0.0260\n",
      "Overfitting Gap:     22.6%\n",
      "\n",
      "Baseline:\n",
      "  Random: 0.0213 (2.13%)\n",
      "  Model:  0.0325 (3.25%)\n",
      "  Improvement: 1.5x\n",
      "\n",
      "================================================================================\n",
      "CLASSIFICATION REPORT\n",
      "================================================================================\n",
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "         Administrative Services      0.016     0.048     0.024       104\n",
      "                     Advertising      0.000     0.000     0.000        53\n",
      "         Agriculture and Farming      0.033     0.176     0.056        34\n",
      "                            Apps      0.033     0.096     0.049       156\n",
      "         Artificial Intelligence      0.017     0.014     0.015       218\n",
      "                   Biotechnology      0.037     0.437     0.068       142\n",
      "            Clothing and Apparel      0.032     0.185     0.055        27\n",
      "           Commerce and Shopping      0.030     0.007     0.012       280\n",
      "         Community and Lifestyle      0.021     0.022     0.021        93\n",
      "            Consumer Electronics      0.000     0.000     0.000       130\n",
      "                  Consumer Goods      0.035     0.049     0.041        61\n",
      "          Content and Publishing      0.000     0.000     0.000        61\n",
      "              Data and Analytics      0.040     0.010     0.016       399\n",
      "                          Design      0.013     0.010     0.011        96\n",
      "                       Education      0.012     0.033     0.017        92\n",
      "                          Energy      0.022     0.017     0.019        59\n",
      "                          Events      0.000     0.000     0.000        24\n",
      "              Financial Services      0.081     0.039     0.052       466\n",
      "               Food and Beverage      0.034     0.090     0.050       100\n",
      "                          Gaming      0.012     0.059     0.020        34\n",
      "         Government and Military      0.000     0.000     0.000        25\n",
      "                        Hardware      0.032     0.003     0.006       304\n",
      "                     Health Care      0.043     0.043     0.043       323\n",
      "          Information Technology      0.051     0.014     0.022       489\n",
      "               Internet Services      0.071     0.018     0.029       385\n",
      "         Lending and Investments      0.040     0.081     0.053       186\n",
      "                   Manufacturing      0.017     0.011     0.013        89\n",
      "         Media and Entertainment      0.000     0.000     0.000       170\n",
      "Messaging and Telecommunications      0.018     0.051     0.027        39\n",
      "                          Mobile      0.032     0.019     0.024       212\n",
      "                 Music and Audio      0.000     0.000     0.000        20\n",
      "               Natural Resources      0.000     0.000     0.000        29\n",
      "          Navigation and Mapping      0.012     0.050     0.020        20\n",
      "                           Other      0.033     0.014     0.019       290\n",
      "                        Payments      0.019     0.038     0.025       131\n",
      "                       Platforms      0.000     0.000     0.000        24\n",
      "            Privacy and Security      0.018     0.053     0.027       113\n",
      "           Professional Services      0.007     0.007     0.007       150\n",
      "                     Real Estate      0.026     0.073     0.039       110\n",
      "             Sales and Marketing      0.039     0.013     0.019       157\n",
      "         Science and Engineering      0.082     0.020     0.032       405\n",
      "                        Software      0.163     0.015     0.027      1019\n",
      "                          Sports      0.011     0.019     0.014        54\n",
      "                  Sustainability      0.125     0.016     0.028        64\n",
      "                  Transportation      0.041     0.031     0.035       192\n",
      "              Travel and Tourism      0.012     0.021     0.015        48\n",
      "                           Video      0.000     0.000     0.000        49\n",
      "\n",
      "                        accuracy                          0.032      7726\n",
      "                       macro avg      0.029     0.040     0.022      7726\n",
      "                    weighted avg      0.055     0.032     0.026      7726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test  = model.predict(X_test)\n",
    "\n",
    "train_acc = accuracy_score(y_train, y_pred_train)\n",
    "test_acc  = accuracy_score(y_test, y_pred_test)\n",
    "test_f1   = f1_score(y_test, y_pred_test, average='weighted')\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"RESULTS (Standard single-label accuracy on (logo, category) pairs)\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Training Accuracy: {train_acc:.4f} ({train_acc*100:.2f}%)\")\n",
    "print(f\"Testing Accuracy:  {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "print(f\"F1-Score (weighted): {test_f1:.4f}\")\n",
    "print(f\"Overfitting Gap:     {(train_acc-test_acc)*100:.1f}%\")\n",
    "\n",
    "random_guess = 1.0 / len(le.classes_)\n",
    "print(f\"\\nBaseline:\")\n",
    "print(f\"  Random: {random_guess:.4f} ({random_guess*100:.2f}%)\")\n",
    "print(f\"  Model:  {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "print(f\"  Improvement: {test_acc/random_guess:.1f}x\")\n",
    "\n",
    "# Classification report only on labels present in y_test\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(f\"{'='*80}\")\n",
    "classes_in_test = np.unique(y_test)\n",
    "target_names = le.inverse_transform(classes_in_test)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        y_pred_test,\n",
    "        labels=classes_in_test,\n",
    "        target_names=target_names,\n",
    "        digits=3\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "607b1d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MEMBERSHIP ACCURACY (PER LOGO, Train SET) ===\n",
      "Train logo-level membership accuracy: 7827/7954 = 0.9840\n",
      "\n",
      "=== MEMBERSHIP ACCURACY (PER LOGO, TEST SET) ===\n",
      "Test logo-level membership accuracy: 251/1989 = 0.1262\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== MEMBERSHIP ACCURACY (PER LOGO, Train SET) ===\")\n",
    "\n",
    "train_unique_logos = np.unique(logo_train_split)\n",
    "correct_logos = 0\n",
    "\n",
    "for logo_idx in train_unique_logos:\n",
    "    rows = np.where(logo_train_split == logo_idx)[0]\n",
    "    preds = le.inverse_transform(y_pred_train[rows])\n",
    "    true_cats = df_features.loc[logo_idx, \"parsed_categories\"]\n",
    "\n",
    "    if any(pred in true_cats for pred in preds):\n",
    "        correct_logos += 1\n",
    "\n",
    "print(f\"Train logo-level membership accuracy: {correct_logos}/{len(train_unique_logos)} = {correct_logos/len(train_unique_logos):.4f}\")\n",
    "\n",
    "\n",
    "print(\"\\n=== MEMBERSHIP ACCURACY (PER LOGO, TEST SET) ===\")\n",
    "\n",
    "test_unique_logos = np.unique(logo_test_split)\n",
    "correct_logos = 0\n",
    "\n",
    "for logo_idx in test_unique_logos:\n",
    "    rows = np.where(logo_test_split == logo_idx)[0]\n",
    "    preds = le.inverse_transform(y_pred_test[rows])\n",
    "    true_cats = df_features.loc[logo_idx, \"parsed_categories\"]\n",
    "\n",
    "    if any(pred in true_cats for pred in preds):\n",
    "        correct_logos += 1\n",
    "\n",
    "print(f\"Test logo-level membership accuracy: {correct_logos}/{len(test_unique_logos)} = {correct_logos/len(test_unique_logos):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b9c29b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

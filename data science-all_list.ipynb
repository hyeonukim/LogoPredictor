{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3179493e-6706-439f-84d4-752cbacf965d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUSINESS LOGO DOMAIN CLASSIFICATION\n",
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA available: True\n",
      "Using device: cuda\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import os\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "import ast\n",
    "\n",
    "print(\"BUSINESS LOGO DOMAIN CLASSIFICATION\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42087470-cdfd-4041-b307-6ffe11fb9589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded 10000 samples\n",
      " Columns: ['uuid', 'name', 'type', 'permalink', 'cb_url', 'rank', 'created_at', 'updated_at', 'legal_name', 'roles', 'domain', 'homepage_url', 'region', 'city', 'address', 'postal_code', 'status', 'short_description', 'num_funding_rounds', 'total_funding_usd', 'total_funding', 'total_funding_currency_code', 'founded_on', 'last_funding_on', 'closed_on', 'employee_count', 'email', 'phone', 'facebook_url', 'linkedin_url', 'twitter_url', 'state_code', 'logo_url', 'country_code', 'category_groups_list', 'category_list', 'new_logo_url']\n",
      " Found 9998 logo files\n",
      "✓ Matched 9990 logos (99.9%)\n",
      " Logos with at least 1 category: 9990\n",
      "✓ Total unique categories (multi-label): 47\n",
      "✓ Total samples (logos with at least 1 matched file): 9990\n",
      "\n",
      "Category frequency distribution (based on individual categories):\n",
      "  Categories with 1 sample:      2861\n",
      "  Categories with 2-4 samples:   819\n",
      "  Categories with 5-9 samples:   200\n",
      "  Categories with 10-19 samples: 75\n",
      "  Categories with 20+ samples:   51\n",
      "\n",
      "Top 20 most common categories:\n",
      "  1. [5076] Software\n",
      "  2. [2378] Financial Services\n",
      "  3. [2301] Information Technology\n",
      "  4. [2043] Science and Engineering\n",
      "  5. [2007] Internet Services\n",
      "  6. [1893] Data and Analytics\n",
      "  7. [1720] Health Care\n",
      "  8. [1455] Hardware\n",
      "  9. [1373] Commerce and Shopping\n",
      " 10. [1373] Other\n",
      " 11. [1085] Artificial Intelligence\n",
      " 12. [1073] Mobile\n",
      " 13. [ 956] Lending and Investments\n",
      " 14. [ 903] Transportation\n",
      " 15. [ 863] Media and Entertainment\n",
      " 16. [ 810] Professional Services\n",
      " 17. [ 778] Sales and Marketing\n",
      " 18. [ 778] Biotechnology\n",
      " 19. [ 753] Apps\n",
      " 20. [ 688] Payments\n"
     ]
    }
   ],
   "source": [
    "csv_path = r\"C:\\BCIT\\data_science\\project\\LogoPredictor\\top10k_logos.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "logo_dir = r\"C:\\BCIT\\data_science\\project\\logo_images\"\n",
    "\n",
    "print(f\" Loaded {len(df)} samples\")\n",
    "print(f\" Columns: {df.columns.tolist()}\")\n",
    "\n",
    "# Get list of available logo files\n",
    "logo_files = os.listdir(logo_dir)\n",
    "logo_files_set = set(logo_files)\n",
    "print(f\" Found {len(logo_files)} logo files\")\n",
    "\n",
    "def clean_name(name):\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    name = str(name).lower().replace(' ', '_').replace('-', '_')\n",
    "    return ''.join(c for c in name if c.isalnum() or c == '_')\n",
    "\n",
    "df['clean_name'] = df['name'].apply(clean_name)\n",
    "\n",
    "\n",
    "matched_rows = []\n",
    "for logo_file in logo_files:\n",
    "    logo_name_raw = os.path.splitext(logo_file)[0]\n",
    "\n",
    "    # Many files may be like \"12345_company_name\", so drop leading ID part\n",
    "    if '_' in logo_name_raw:\n",
    "        logo_name = '_'.join(logo_name_raw.split('_', 1)[1:])\n",
    "    else:\n",
    "        logo_name = logo_name_raw\n",
    "    \n",
    "    logo_cleaned = clean_name(logo_name)\n",
    "    \n",
    "    # Find matching row in df\n",
    "    matches = df[df['clean_name'] == logo_cleaned]\n",
    "    if len(matches) > 0:\n",
    "        row = matches.iloc[0].copy()\n",
    "        row['logo_filename'] = logo_file\n",
    "        matched_rows.append(row)\n",
    "\n",
    "df_matched = pd.DataFrame(matched_rows)\n",
    "print(f\"✓ Matched {len(df_matched)} logos ({len(df_matched)/len(logo_files)*100:.1f}%)\")\n",
    "\n",
    "def parse_categories(x):\n",
    "    \"\"\"\n",
    "    Convert the raw category_groups_list string into a Python list.\n",
    "    Handles:\n",
    "      - \"['Software', 'AI']\"   (Python-list style)\n",
    "      - \"Software, AI\"        (comma-separated)\n",
    "      - NaNs                  (returns [])\n",
    "    \"\"\"\n",
    "    if pd.isna(x):\n",
    "        return []\n",
    "    \n",
    "    x = str(x).strip()\n",
    "    \n",
    "    # Try to parse as Python list: \"['A', 'B']\"\n",
    "    if x.startswith('[') and x.endswith(']'):\n",
    "        try:\n",
    "            parsed = ast.literal_eval(x)\n",
    "            # Ensure list of strings\n",
    "            return [str(c).strip() for c in parsed]\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "    # Fallback: comma-separated string\n",
    "    return [c.strip() for c in x.split(',') if c.strip()]\n",
    "\n",
    "df_matched[\"parsed_categories\"] = df_matched[\"category_groups_list\"].apply(parse_categories)\n",
    "\n",
    "df_filtered = df_matched[df_matched[\"parsed_categories\"].map(len) > 0].copy()\n",
    "df_filtered = df_filtered.reset_index(drop=True)\n",
    "print(f\" Logos with at least 1 category: {len(df_filtered)}\")\n",
    "\n",
    "cat_counter = Counter()\n",
    "for cats in df_matched[\"parsed_categories\"]:\n",
    "    cat_counter.update(cats)\n",
    "\n",
    "# Convert to Series for convenience\n",
    "category_counts = pd.Series(cat_counter).sort_values(ascending=False)\n",
    "\n",
    "print(f\"✓ Total unique categories (multi-label): {len(category_counts)}\")\n",
    "print(f\"✓ Total samples (logos with at least 1 matched file): {len(df_matched)}\")\n",
    "\n",
    "# Distribution of category frequencies\n",
    "print(\"\\nCategory frequency distribution (based on individual categories):\")\n",
    "freq_values = df_matched['category_groups_list'].value_counts()\n",
    "print(f\"  Categories with 1 sample:      {(freq_values == 1).sum()}\")\n",
    "print(f\"  Categories with 2-4 samples:   {((freq_values >= 2) & (freq_values <= 4)).sum()}\")\n",
    "print(f\"  Categories with 5-9 samples:   {((freq_values >= 5) & (freq_values <= 9)).sum()}\")\n",
    "print(f\"  Categories with 10-19 samples: {((freq_values >= 10) & (freq_values < 20)).sum()}\")\n",
    "print(f\"  Categories with 20+ samples:   {(freq_values >= 20).sum()}\")\n",
    "\n",
    "print(\"\\nTop 20 most common categories:\")\n",
    "for i, (cat, count) in enumerate(category_counts.head(20).items(), 1):\n",
    "    short_cat = cat[:70] + \"...\" if len(cat) > 70 else cat\n",
    "    print(f\"{i:3d}. [{count:4d}] {short_cat}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "240508b3-4654-4781-896f-4e5b0f982ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ResNet18 features...\n",
      "  200/9990\n",
      "  400/9990\n",
      "  600/9990\n",
      "  800/9990\n",
      "  1000/9990\n",
      "  1200/9990\n",
      "  1400/9990\n",
      "  1600/9990\n",
      "  1800/9990\n",
      "  2000/9990\n",
      "  2200/9990\n",
      "  2400/9990\n",
      "  2600/9990\n",
      "  2800/9990\n",
      "  3000/9990\n",
      "  3200/9990\n",
      "  3400/9990\n",
      "  3600/9990\n",
      "  3800/9990\n",
      "  4000/9990\n",
      "  4200/9990\n",
      "  4400/9990\n",
      "  4600/9990\n",
      "  4800/9990\n",
      "  5000/9990\n",
      "  5200/9990\n",
      "  5400/9990\n",
      "  5600/9990\n",
      "  5800/9990\n",
      "  6000/9990\n",
      "  6200/9990\n",
      "  6400/9990\n",
      "  6600/9990\n",
      "  6800/9990\n",
      "  7000/9990\n",
      "  7200/9990\n",
      "  7400/9990\n",
      "  7600/9990\n",
      "  7800/9990\n",
      "  8000/9990\n",
      "  8200/9990\n",
      "  8400/9990\n",
      "  8600/9990\n",
      "  8800/9990\n",
      "  9000/9990\n",
      "  9200/9990\n",
      "  9400/9990\n",
      "  9600/9990\n",
      "  9800/9990\n",
      "\n",
      "Done. Extracted 9943 features (failed: 47)\n",
      " Feature matrix shape X: (9943, 512)\n",
      " df_features rows: 9943\n"
     ]
    }
   ],
   "source": [
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet = nn.Sequential(*list(resnet.children())[:-1])  # drop final FC layer\n",
    "resnet = resnet.to(device)\n",
    "resnet.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "features_list = []\n",
    "success_indices = []   # indices in df_filtered that succeeded\n",
    "failed = 0\n",
    "\n",
    "print(\"\\nExtracting ResNet18 features...\")\n",
    "with torch.no_grad():\n",
    "    for idx, row in df_filtered.iterrows():\n",
    "        logo_path = os.path.join(logo_dir, row[\"logo_filename\"])\n",
    "        try:\n",
    "            img = Image.open(logo_path).convert(\"RGB\")\n",
    "            img_tensor = transform(img).unsqueeze(0).to(device)  # [1,3,224,224]\n",
    "\n",
    "            # [1,512,1,1] -> [512]\n",
    "            feat = resnet(img_tensor).view(-1).cpu().numpy()\n",
    "            features_list.append(feat)\n",
    "            success_indices.append(idx)\n",
    "\n",
    "            if len(features_list) % 200 == 0:\n",
    "                print(f\"  {len(features_list)}/{len(df_filtered)}\")\n",
    "        except Exception:\n",
    "            failed += 1\n",
    "\n",
    "X = np.stack(features_list)   # [num_successful_logos, 512]\n",
    "df_features = df_filtered.loc[success_indices].reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nDone. Extracted {len(X)} features (failed: {failed})\")\n",
    "print(\" Feature matrix shape X:\", X.shape)\n",
    "print(\" df_features rows:\", len(df_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e34d516d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After exploding into (logo, category) pairs:\n",
      " X_expanded shape: (38012, 512)\n",
      " y length: 38012\n",
      " Example pairs:\n",
      "  logo_idx=0, category=Financial Services\n",
      "  logo_idx=0, category=Hardware\n",
      "  logo_idx=0, category=Internet Services\n",
      "  logo_idx=0, category=Lending and Investments\n",
      "  logo_idx=0, category=Mobile\n"
     ]
    }
   ],
   "source": [
    "tmp = df_features[[\"parsed_categories\"]].copy()\n",
    "tmp = tmp.explode(\"parsed_categories\")   # one row per (logo, category)\n",
    "tmp = tmp.rename(columns={\"parsed_categories\": \"category\"})\n",
    "tmp = tmp.reset_index().rename(columns={\"index\": \"logo_idx\"})\n",
    "# columns: ['logo_idx', 'category']\n",
    "# logo_idx now runs from 0 .. len(df_features)-1 and matches X\n",
    "\n",
    "logo_indices = tmp[\"logo_idx\"].values          # which row in X to use\n",
    "X_expanded = X[logo_indices]                   # [num_pairs, 512]\n",
    "y = tmp[\"category\"].values                     # [num_pairs]\n",
    "\n",
    "print(\"\\nAfter exploding into (logo, category) pairs:\")\n",
    "print(\" X_expanded shape:\", X_expanded.shape)\n",
    "print(\" y length:\", len(y))\n",
    "print(\" Example pairs:\")\n",
    "for i in range(5):\n",
    "    print(f\"  logo_idx={logo_indices[i]}, category={y[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "30e0ce17-aaf6-4971-89c0-a7118986fe35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 47 categories retained (single-label).\n",
      "  Samples per category: min=80, max=5052, mean=808.8\n",
      "\n",
      "Unique logos (after feature extraction): 9943\n",
      "\n",
      "Train rows: 30286, Test rows: 7726\n",
      "\n",
      "Train label distribution (first 10 classes):\n",
      "[ 382  226  125  592  864  632  136 1085  371  460]\n",
      "Test label distribution (first 10 classes):\n",
      "[104  53  34 156 218 142  27 280  93 130]\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "print(f\"\\n {len(le.classes_)} categories retained (single-label).\")\n",
    "binc = np.bincount(y_encoded)\n",
    "print(f\"  Samples per category: min={np.min(binc)}, max={np.max(binc)}, mean={np.mean(binc):.1f}\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_expanded)\n",
    "\n",
    "# Split by logo, so each logo is only in train OR test\n",
    "unique_logos = np.unique(logo_indices)\n",
    "print(f\"\\nUnique logos (after feature extraction): {len(unique_logos)}\")\n",
    "\n",
    "logo_train_ids, logo_test_ids = train_test_split(\n",
    "    unique_logos,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_mask = np.isin(logo_indices, logo_train_ids)\n",
    "test_mask  = np.isin(logo_indices, logo_test_ids)\n",
    "\n",
    "X_train = X_scaled[train_mask]\n",
    "y_train = y_encoded[train_mask]\n",
    "logo_train_split = logo_indices[train_mask]\n",
    "\n",
    "X_test  = X_scaled[test_mask]\n",
    "y_test  = y_encoded[test_mask]\n",
    "logo_test_split = logo_indices[test_mask]\n",
    "\n",
    "print(f\"\\nTrain rows: {len(X_train)}, Test rows: {len(X_test)}\")\n",
    "\n",
    "print(\"\\nTrain label distribution (first 10 classes):\")\n",
    "print(np.bincount(y_train)[:10])\n",
    "print(\"Test label distribution (first 10 classes):\")\n",
    "print(np.bincount(y_test)[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85962fa0",
   "metadata": {},
   "source": [
    "# Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1442528a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_membership_accuracy(model, X_train, y_train, X_test, y_test,\n",
    "                                 logo_train_split, logo_test_split, le, df_features,\n",
    "                                 name=\"MODEL\"):\n",
    "    print(f\"\\n\\n=== {name} — MEMBERSHIP ACCURACY ONLY ===\")\n",
    "\n",
    "    # ---- TRAIN SET ----\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_train_pred_labels = le.inverse_transform(y_train_pred)\n",
    "\n",
    "    train_unique_logos = np.unique(logo_train_split)\n",
    "    correct_train = 0\n",
    "\n",
    "    for logo_idx in train_unique_logos:\n",
    "        rows = np.where(logo_train_split == logo_idx)[0]\n",
    "        preds = y_train_pred_labels[rows]\n",
    "        true_cats = df_features.loc[logo_idx, \"parsed_categories\"]\n",
    "        \n",
    "        if any(p in true_cats for p in preds):\n",
    "            correct_train += 1\n",
    "\n",
    "    train_membership_acc = correct_train / len(train_unique_logos)\n",
    "\n",
    "\n",
    "    # ---- TEST SET ----\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_pred_labels = le.inverse_transform(y_test_pred)\n",
    "\n",
    "    test_unique_logos = np.unique(logo_test_split)\n",
    "    correct_test = 0\n",
    "\n",
    "    for logo_idx in test_unique_logos:\n",
    "        rows = np.where(logo_test_split == logo_idx)[0]\n",
    "        preds = y_test_pred_labels[rows]\n",
    "        true_cats = df_features.loc[logo_idx, \"parsed_categories\"]\n",
    "\n",
    "        if any(p in true_cats for p in preds):\n",
    "            correct_test += 1\n",
    "\n",
    "    test_membership_acc = correct_test / len(test_unique_logos)\n",
    "\n",
    "\n",
    "    # ---- Output ----\n",
    "    print(f\"\\n{name} — TRAIN membership accuracy:\")\n",
    "    print(f\"  {correct_train}/{len(train_unique_logos)} = {train_membership_acc:.4f}\")\n",
    "\n",
    "    print(f\"\\n{name} — TEST membership accuracy:\")\n",
    "    print(f\"  {correct_test}/{len(test_unique_logos)} = {test_membership_acc:.4f}\")\n",
    "\n",
    "    return train_membership_acc, test_membership_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b557de9e",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0ce5d677-ae08-4abb-bf66-78ce3d7754ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training RandomForestClassifier...\n",
      "\n",
      "\n",
      "=== RandomForest — MEMBERSHIP ACCURACY ONLY ===\n",
      "\n",
      "RandomForest — TRAIN membership accuracy:\n",
      "  7827/7954 = 0.9840\n",
      "\n",
      "RandomForest — TEST membership accuracy:\n",
      "  251/1989 = 0.1262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9840331908473724, 0.12619406737053795)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=25,\n",
    "    min_samples_split=8,\n",
    "    min_samples_leaf=3,\n",
    "    max_features='sqrt',\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining RandomForestClassifier...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "evaluate_membership_accuracy(\n",
    "    model=model,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    logo_train_split=logo_train_split,\n",
    "    logo_test_split=logo_test_split,\n",
    "    le=le,\n",
    "    df_features=df_features,\n",
    "    name=\"RandomForest\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22dc3e90",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "64b9c29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training LogisticRegression (OvR) on X_train...\n",
      "LogisticRegression training complete.\n",
      "\n",
      "\n",
      "=== LogisticRegression — MEMBERSHIP ACCURACY ONLY ===\n",
      "\n",
      "LogisticRegression — TRAIN membership accuracy:\n",
      "  1767/7954 = 0.2222\n",
      "\n",
      "LogisticRegression — TEST membership accuracy:\n",
      "  121/1989 = 0.0608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2221523761629369, 0.06083459024635495)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(\n",
    "    multi_class=\"ovr\",\n",
    "    max_iter=2000,\n",
    "    C=1.0,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"\\nTraining LogisticRegression (OvR) on X_train...\")\n",
    "logreg.fit(X_train, y_train)\n",
    "print(\"LogisticRegression training complete.\")\n",
    "\n",
    "evaluate_membership_accuracy(\n",
    "    model=logreg,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    logo_train_split=logo_train_split,\n",
    "    logo_test_split=logo_test_split,\n",
    "    le=le,\n",
    "    df_features=df_features,\n",
    "    name=\"LogisticRegression\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186db7b2",
   "metadata": {},
   "source": [
    "# ResNet Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e792f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training ResNet-style MLP head on embeddings...\n",
      "Epoch  1 | Train loss: 3.4487 | Train acc: 0.1217 | Test acc: 0.1307\n",
      "Epoch  2 | Train loss: 3.3140 | Train acc: 0.1315 | Test acc: 0.1311\n",
      "Epoch  3 | Train loss: 3.2149 | Train acc: 0.1341 | Test acc: 0.1252\n",
      "Epoch  4 | Train loss: 3.1011 | Train acc: 0.1363 | Test acc: 0.1222\n",
      "Epoch  5 | Train loss: 2.9794 | Train acc: 0.1391 | Test acc: 0.1239\n",
      "Epoch  6 | Train loss: 2.8564 | Train acc: 0.1433 | Test acc: 0.1032\n",
      "Epoch  7 | Train loss: 2.7512 | Train acc: 0.1496 | Test acc: 0.1134\n",
      "Epoch  8 | Train loss: 2.6584 | Train acc: 0.1507 | Test acc: 0.1117\n",
      "Epoch  9 | Train loss: 2.5749 | Train acc: 0.1530 | Test acc: 0.0982\n",
      "Epoch 10 | Train loss: 2.5096 | Train acc: 0.1539 | Test acc: 0.1020\n",
      "\n",
      "\n",
      "=== ResNet-MLP — MEMBERSHIP ACCURACY ONLY ===\n",
      "\n",
      "ResNet-MLP — TRAIN membership accuracy:\n",
      "  6777/7954 = 0.8520\n",
      "\n",
      "ResNet-MLP — TEST membership accuracy:\n",
      "  788/1989 = 0.3962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.852024138798089, 0.3961789844142785)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "\n",
    "train_ds = EmbeddingDataset(X_train, y_train)\n",
    "test_ds  = EmbeddingDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=256, shuffle=False)\n",
    "\n",
    "\n",
    "class ResNetStyleHead(nn.Module):\n",
    "    \"\"\"\n",
    "    A small residual MLP head on top of 512-d ResNet embeddings:\n",
    "      x -> FC(512) -> ReLU -> FC(512) -> +x -> ReLU -> FC(num_classes)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim=512, num_classes=47):  # 47 if that's your class count\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc_out = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, in_dim]\n",
    "        residual = x\n",
    "        out = F.relu(self.fc1(x))\n",
    "        out = self.fc2(out)\n",
    "        out = F.relu(out + residual)  # residual connection\n",
    "        out = self.fc_out(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "num_classes = len(le.classes_)\n",
    "resnet_head = ResNetStyleHead(in_dim=X_train.shape[1], num_classes=num_classes).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(resnet_head.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def train_resnet_head_one_epoch():\n",
    "    resnet_head.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = resnet_head(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        total_correct += (preds == yb).sum().item()\n",
    "        total += xb.size(0)\n",
    "\n",
    "    return total_loss / total, total_correct / total\n",
    "\n",
    "\n",
    "def eval_resnet_head(loader):\n",
    "    resnet_head.eval()\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            logits = resnet_head(xb)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            total_correct += (preds == yb).sum().item()\n",
    "            total += xb.size(0)\n",
    "\n",
    "    acc = total_correct / total\n",
    "    return acc\n",
    "\n",
    "\n",
    "print(\"\\nTraining ResNet-style MLP head on embeddings...\")\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc_resnet = train_resnet_head_one_epoch()\n",
    "    test_acc_resnet = eval_resnet_head(test_loader)\n",
    "    print(f\"Epoch {epoch+1:2d} | Train loss: {train_loss:.4f} | \"\n",
    "          f\"Train acc: {train_acc_resnet:.4f} | Test acc: {test_acc_resnet:.4f}\")\n",
    "\n",
    "\n",
    "class ResNetHeadWrapper:\n",
    "    def __init__(self, net, device, batch_size=256):\n",
    "        self.net = net\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        X: numpy array of shape [N, D] (same as X_train / X_test)\n",
    "        returns: numpy array of predicted class indices [N]\n",
    "        \"\"\"\n",
    "        self.net.eval()\n",
    "        X_np = X.astype(np.float32)\n",
    "        preds_all = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(X_np), self.batch_size):\n",
    "                xb = torch.from_numpy(X_np[i:i + self.batch_size]).to(self.device)\n",
    "                logits = self.net(xb)\n",
    "                preds = logits.argmax(dim=1).cpu().numpy()\n",
    "                preds_all.append(preds)\n",
    "\n",
    "        return np.concatenate(preds_all)\n",
    "\n",
    "\n",
    "resnet_head_sklearn = ResNetHeadWrapper(resnet_head, device)\n",
    "\n",
    "evaluate_membership_accuracy(\n",
    "    model=resnet_head_sklearn,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    logo_train_split=logo_train_split,\n",
    "    logo_test_split=logo_test_split,\n",
    "    le=le,\n",
    "    df_features=df_features,\n",
    "    name=\"ResNet-MLP\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3e22cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

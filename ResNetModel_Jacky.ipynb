{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88e27234-b7ac-4f3b-b487-5d445208e910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV to check columns...\n",
      "\n",
      "============================================================\n",
      "COLUMN NAMES IN YOUR CSV:\n",
      "============================================================\n",
      "1. uuid\n",
      "2. name\n",
      "3. type\n",
      "4. permalink\n",
      "5. cb_url\n",
      "6. rank\n",
      "7. created_at\n",
      "8. updated_at\n",
      "9. legal_name\n",
      "10. roles\n",
      "11. domain\n",
      "12. homepage_url\n",
      "13. region\n",
      "14. city\n",
      "15. address\n",
      "16. postal_code\n",
      "17. status\n",
      "18. short_description\n",
      "19. num_funding_rounds\n",
      "20. total_funding_usd\n",
      "21. total_funding\n",
      "22. total_funding_currency_code\n",
      "23. founded_on\n",
      "24. last_funding_on\n",
      "25. closed_on\n",
      "26. employee_count\n",
      "27. email\n",
      "28. phone\n",
      "29. facebook_url\n",
      "30. linkedin_url\n",
      "31. twitter_url\n",
      "32. state_code\n",
      "33. logo_url\n",
      "34. country_code\n",
      "35. category_groups_list\n",
      "36. category_list\n",
      "37. new_logo_url\n",
      "\n",
      "============================================================\n",
      "FIRST FEW ROWS:\n",
      "============================================================\n",
      "                                   uuid      name          type  \\\n",
      "0  1a410398-3a72-5882-99b8-6318cf594850  SoftBank  organization   \n",
      "1  2cc3a5de-2303-aa00-cd1a-50bd96420392    Klarna  organization   \n",
      "2  84c5275e-2a2f-e43a-1ff1-1a5f7c79975f    Apollo  organization   \n",
      "3  0c4f065f-524f-fb08-8c17-305b43755705    Nubank  organization   \n",
      "4  00daca16-8311-454b-84e0-24a40d16be9c    Antler  organization   \n",
      "\n",
      "                      permalink  \\\n",
      "0                      softbank   \n",
      "1                        klarna   \n",
      "2  apollo-global-management-llc   \n",
      "3                        nubank   \n",
      "4                   antler-be9c   \n",
      "\n",
      "                                              cb_url  rank  \\\n",
      "0   https://www.crunchbase.com/organization/softbank   1.0   \n",
      "1     https://www.crunchbase.com/organization/klarna   2.0   \n",
      "2  https://www.crunchbase.com/organization/apollo...   3.0   \n",
      "3     https://www.crunchbase.com/organization/nubank   4.0   \n",
      "4  https://www.crunchbase.com/organization/antler...   5.0   \n",
      "\n",
      "           created_at          updated_at                     legal_name  \\\n",
      "0   8/8/2008 21:48:34  5/12/2021 14:06:57           SoftBank Group Corp.   \n",
      "1   3/31/2010 3:36:01  5/28/2021 17:32:41                 Klarna Bank AB   \n",
      "2   8/19/2011 1:49:04   4/6/2021 14:24:49  Apollo Global Management Inc.   \n",
      "3  9/25/2014 10:33:05   6/9/2021 19:05:26             Nu Pagamentos S.A.   \n",
      "4   4/9/2018 11:16:43  6/17/2021 14:15:36      Antler Innovation Pte Ltd   \n",
      "\n",
      "              roles  ...            phone  \\\n",
      "0  investor,company  ...  +81-3-6889-2000   \n",
      "1  investor,company  ...                    \n",
      "2  investor,company  ...     212-515-3200   \n",
      "3  investor,company  ...    0800 591 2117   \n",
      "4          investor  ...                    \n",
      "\n",
      "                             facebook_url  \\\n",
      "0        http://www.facebook.com/SoftBank   \n",
      "1          http://www.facebook.com/Klarna   \n",
      "2                                           \n",
      "3         https://www.facebook.com/nubank   \n",
      "4  https://www.facebook.com/antlerglobal/   \n",
      "\n",
      "                                        linkedin_url  \\\n",
      "0     https://www.linkedin.com/company/softbankgroup   \n",
      "1            https://www.linkedin.com/company/klarna   \n",
      "2  https://www.linkedin.com/company/apollo-global...   \n",
      "3            https://www.linkedin.com/company/nubank   \n",
      "4     https://www.linkedin.com/company/antlerglobal/   \n",
      "\n",
      "                          twitter_url state_code  \\\n",
      "0  https://twitter.com/softbank_group              \n",
      "1           http://twitter.com/klarna              \n",
      "2    https://twitter.com/apolloglobal         NY   \n",
      "3          https://twitter.com/nubank              \n",
      "4    https://twitter.com/AntlerGlobal              \n",
      "\n",
      "                                            logo_url country_code  \\\n",
      "0  https://res.cloudinary.com/crunchbase-producti...          JPN   \n",
      "1  https://res.cloudinary.com/crunchbase-producti...          SWE   \n",
      "2  https://res.cloudinary.com/crunchbase-producti...          USA   \n",
      "3  https://res.cloudinary.com/crunchbase-producti...          BRA   \n",
      "4  https://res.cloudinary.com/crunchbase-producti...          SGP   \n",
      "\n",
      "                                category_groups_list  \\\n",
      "0  Financial Services,Hardware,Internet Services,...   \n",
      "1  Commerce and Shopping,Financial Services,Payments   \n",
      "2  Financial Services,Lending and Investments,Rea...   \n",
      "3  Financial Services,Lending and Investments,Pay...   \n",
      "4         Financial Services,Lending and Investments   \n",
      "\n",
      "                                       category_list  \\\n",
      "0         Banking,Internet,Mobile,Telecommunications   \n",
      "1                E-Commerce,Finance,FinTech,Payments   \n",
      "2  Asset Management,Credit,Finance,Financial Serv...   \n",
      "3  Banking,Credit Cards,Financial Services,FinTec...   \n",
      "4                                    Venture Capital   \n",
      "\n",
      "                                        new_logo_url  \n",
      "0  https://images.crunchbase.com/image/upload/c_p...  \n",
      "1  https://images.crunchbase.com/image/upload/c_p...  \n",
      "2  https://images.crunchbase.com/image/upload/c_p...  \n",
      "3  https://images.crunchbase.com/image/upload/c_p...  \n",
      "4  https://images.crunchbase.com/image/upload/c_p...  \n",
      "\n",
      "[5 rows x 37 columns]\n",
      "\n",
      "============================================================\n",
      "COLUMNS CONTAINING 'CATEGORY':\n",
      "============================================================\n",
      "  - category_groups_list\n",
      "    Sample value: Financial Services,Hardware,Internet Services,Lending and Investments,Mobile\n",
      "  - category_list\n",
      "    Sample value: Banking,Internet,Mobile,Telecommunications\n",
      "\n",
      "============================================================\n",
      "COLUMNS CONTAINING 'GROUP':\n",
      "============================================================\n",
      "  - category_groups_list\n",
      "    Sample value: Financial Services,Hardware,Internet Services,Lending and Investments,Mobile\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Update with your CSV path\n",
    "csv_path = os.path.expanduser('~/Downloads/top10k_logos.csv')\n",
    "\n",
    "print(\"Loading CSV to check columns...\")\n",
    "df = pd.read_csv(csv_path, nrows=5)  # Only load first 5 rows\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COLUMN NAMES IN YOUR CSV:\")\n",
    "print(\"=\"*60)\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i}. {col}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FIRST FEW ROWS:\")\n",
    "print(\"=\"*60)\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COLUMNS CONTAINING 'CATEGORY':\")\n",
    "print(\"=\"*60)\n",
    "category_cols = [col for col in df.columns if 'category' in col.lower()]\n",
    "if category_cols:\n",
    "    for col in category_cols:\n",
    "        print(f\"  - {col}\")\n",
    "        print(f\"    Sample value: {df[col].iloc[0]}\")\n",
    "else:\n",
    "    print(\"  No columns with 'category' found\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COLUMNS CONTAINING 'GROUP':\")\n",
    "print(\"=\"*60)\n",
    "group_cols = [col for col in df.columns if 'group' in col.lower()]\n",
    "if group_cols:\n",
    "    for col in group_cols:\n",
    "        print(f\"  - {col}\")\n",
    "        print(f\"    Sample value: {df[col].iloc[0]}\")\n",
    "else:\n",
    "    print(\"  No columns with 'group' found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "355e6844-344f-41c8-8c27-48fd215ba982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CREATING CLEAN CSV FOR TRAINING\n",
      "============================================================\n",
      "\n",
      "Step 1: Reading logo files...\n",
      "Found 9896 logo files\n",
      "\n",
      "Step 2: Loading CSV...\n",
      "Loaded 10000 rows\n",
      "Kept columns: uuid, name, category_groups_list\n",
      "\n",
      "Step 3: Filtering rows...\n",
      "Removed 0 rows without categories\n",
      "\n",
      "Step 4: Matching logos to companies...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching: 100%|███████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 32706.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Matched: 9988 companies with logos\n",
      "❌ Unmatched: 12 companies without logos\n",
      "\n",
      "Example unmatched companies:\n",
      "  - Ever/Body\n",
      "  - The/Studio\n",
      "  - ATTN:\n",
      "  - Care/of\n",
      "  - Oak HC/FT\n",
      "\n",
      "Removed 12 rows without logos\n",
      "Remaining rows: 9988\n",
      "\n",
      "Step 5: Filtering to top 50 categories...\n",
      "\n",
      "Top 10 categories:\n",
      "  Software: 5088 samples\n",
      "  Financial Services: 2376 samples\n",
      "  Information Technology: 2307 samples\n",
      "  Science and Engineering: 2054 samples\n",
      "  Internet Services: 2013 samples\n",
      "  Data and Analytics: 1903 samples\n",
      "  Health Care: 1720 samples\n",
      "  Hardware: 1463 samples\n",
      "  Other: 1377 samples\n",
      "  Commerce and Shopping: 1371 samples\n",
      "\n",
      "Kept 9988 samples with top categories (removed 0)\n",
      "\n",
      "Step 6: Randomly sampling 1000 samples...\n",
      "Kept 1000 samples\n",
      "\n",
      "Step 7: Saving clean CSV...\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "Original CSV: 10000 rows, 8.97 MB\n",
      "Clean CSV: 1000 rows, 0.13 MB\n",
      "Size reduction: 98.6%\n",
      "\n",
      "Columns in clean CSV: uuid, name, category_groups_list, logo_filename\n",
      "\n",
      "Unique categories: 47\n",
      "Average categories per company: 3.81\n",
      "\n",
      "Output saved to: C:\\Users\\jchen/Downloads/clean_training_data.csv\n",
      "\n",
      "✅ Ready for training! Use this CSV in your training script.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "# Configuration\n",
    "logo_dir = os.path.expanduser('~/Downloads/logo_images')\n",
    "input_csv = os.path.expanduser('~/Downloads/top10k_logos.csv')\n",
    "output_csv = os.path.expanduser('~/Downloads/clean_training_data.csv')\n",
    "target_column = 'category_groups_list'  # or 'category_groups_list'\n",
    "\n",
    "# Optional filtering\n",
    "max_categories = 50  # Set to None to keep all categories\n",
    "max_samples = 1000   # Set to None to keep all samples\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CREATING CLEAN CSV FOR TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Step 1: Load logo files\n",
    "print(\"\\nStep 1: Reading logo files...\")\n",
    "logo_files = {}\n",
    "for filename in os.listdir(logo_dir):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        parts = filename.split('_', 1)\n",
    "        if len(parts) >= 2:\n",
    "            name = os.path.splitext(parts[1])[0]\n",
    "            logo_files[name.lower()] = filename\n",
    "\n",
    "print(f\"Found {len(logo_files)} logo files\")\n",
    "\n",
    "# Step 2: Load CSV with only necessary columns\n",
    "print(\"\\nStep 2: Loading CSV...\")\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "# Keep only essential columns\n",
    "essential_columns = ['uuid', 'name', target_column]\n",
    "df = df[essential_columns].copy()\n",
    "\n",
    "print(f\"Loaded {len(df)} rows\")\n",
    "print(f\"Kept columns: {', '.join(essential_columns)}\")\n",
    "\n",
    "# Step 3: Remove rows without categories\n",
    "print(\"\\nStep 3: Filtering rows...\")\n",
    "original_count = len(df)\n",
    "df = df[df[target_column].notna()].copy()\n",
    "print(f\"Removed {original_count - len(df)} rows without categories\")\n",
    "\n",
    "# Step 4: Match logos\n",
    "print(\"\\nStep 4: Matching logos to companies...\")\n",
    "matched_files = []\n",
    "unmatched_count = 0\n",
    "unmatched_examples = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Matching\"):\n",
    "    csv_name = str(row['name']).strip()\n",
    "    csv_name_lower = csv_name.lower()\n",
    "    \n",
    "    if csv_name_lower in logo_files:\n",
    "        matched_files.append(logo_files[csv_name_lower])\n",
    "    else:\n",
    "        # Try without spaces/hyphens/dots\n",
    "        csv_name_clean = csv_name_lower.replace(' ', '').replace('-', '').replace('.', '')\n",
    "        found = False\n",
    "        for logo_name, logo_file in logo_files.items():\n",
    "            logo_name_clean = logo_name.replace(' ', '').replace('-', '').replace('.', '')\n",
    "            if csv_name_clean == logo_name_clean:\n",
    "                matched_files.append(logo_file)\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            matched_files.append(None)\n",
    "            unmatched_count += 1\n",
    "            if len(unmatched_examples) < 10:\n",
    "                unmatched_examples.append(csv_name)\n",
    "\n",
    "df['logo_filename'] = matched_files\n",
    "\n",
    "print(f\"\\n✅ Matched: {len(df) - unmatched_count} companies with logos\")\n",
    "print(f\"❌ Unmatched: {unmatched_count} companies without logos\")\n",
    "\n",
    "if unmatched_count > 0:\n",
    "    print(f\"\\nExample unmatched companies:\")\n",
    "    for name in unmatched_examples[:5]:\n",
    "        print(f\"  - {name}\")\n",
    "\n",
    "# Remove rows without matching logos\n",
    "before_removal = len(df)\n",
    "df = df[df['logo_filename'].notna()].copy()\n",
    "print(f\"\\nRemoved {before_removal - len(df)} rows without logos\")\n",
    "print(f\"Remaining rows: {len(df)}\")\n",
    "\n",
    "if len(df) == 0:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ERROR: No companies matched with logos!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Debugging info:\")\n",
    "    print(f\"Logo files found: {len(logo_files)}\")\n",
    "    print(f\"CSV rows: {before_removal}\")\n",
    "    print(\"\\nSample logo file names:\")\n",
    "    for name, file in list(logo_files.items())[:5]:\n",
    "        print(f\"  '{name}' -> {file}\")\n",
    "    print(\"\\nThis might be a case sensitivity or naming issue.\")\n",
    "    print(\"=\"*60)\n",
    "    exit()\n",
    "\n",
    "# Step 5: Filter to top N categories (optional)\n",
    "if max_categories:\n",
    "    print(f\"\\nStep 5: Filtering to top {max_categories} categories...\")\n",
    "    \n",
    "    all_categories = []\n",
    "    for cats in df[target_column]:\n",
    "        if pd.notna(cats):\n",
    "            all_categories.extend([cat.strip() for cat in str(cats).split(',')])\n",
    "    \n",
    "    category_counts = Counter(all_categories)\n",
    "    top_categories = set([cat for cat, _ in category_counts.most_common(max_categories)])\n",
    "    \n",
    "    print(f\"\\nTop {min(10, max_categories)} categories:\")\n",
    "    for cat, count in category_counts.most_common(min(10, max_categories)):\n",
    "        print(f\"  {cat}: {count} samples\")\n",
    "    \n",
    "    # Keep only rows with at least one top category\n",
    "    def has_top_category(cats):\n",
    "        if pd.isna(cats):\n",
    "            return False\n",
    "        cat_list = [cat.strip() for cat in str(cats).split(',')]\n",
    "        return any(cat in top_categories for cat in cat_list)\n",
    "    \n",
    "    before_filter = len(df)\n",
    "    df = df[df[target_column].apply(has_top_category)].copy()\n",
    "    print(f\"\\nKept {len(df)} samples with top categories (removed {before_filter - len(df)})\")\n",
    "\n",
    "# Step 6: Limit to max_samples (optional)\n",
    "if max_samples and len(df) > max_samples:\n",
    "    print(f\"\\nStep 6: Randomly sampling {max_samples} samples...\")\n",
    "    df = df.sample(n=max_samples, random_state=42).reset_index(drop=True)\n",
    "    print(f\"Kept {len(df)} samples\")\n",
    "\n",
    "# Step 7: Save clean CSV\n",
    "print(f\"\\nStep 7: Saving clean CSV...\")\n",
    "df = df.reset_index(drop=True)\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "# Calculate file sizes\n",
    "original_size = os.path.getsize(input_csv) / 1024 / 1024\n",
    "new_size = os.path.getsize(output_csv) / 1024 / 1024\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Original CSV: {original_count} rows, {original_size:.2f} MB\")\n",
    "print(f\"Clean CSV: {len(df)} rows, {new_size:.2f} MB\")\n",
    "print(f\"Size reduction: {(1 - new_size/original_size) * 100:.1f}%\")\n",
    "print(f\"\\nColumns in clean CSV: {', '.join(df.columns)}\")\n",
    "\n",
    "# Category statistics\n",
    "all_cats = []\n",
    "for cats in df[target_column]:\n",
    "    if pd.notna(cats):\n",
    "        all_cats.extend([cat.strip() for cat in str(cats).split(',')])\n",
    "\n",
    "unique_categories = len(set(all_cats))\n",
    "print(f\"\\nUnique categories: {unique_categories}\")\n",
    "print(f\"Average categories per company: {len(all_cats) / len(df):.2f}\")\n",
    "print(f\"\\nOutput saved to: {output_csv}\")\n",
    "print(\"\\n✅ Ready for training! Use this CSV in your training script.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5a4633d-16fa-494d-8d1d-b4f8c4be8bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Checking for existing logo files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating logos: 100%|██████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 8827.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 samples with existing logos\n",
      "Found 0 unique categories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 369\u001b[39m\n\u001b[32m    366\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining curves saved to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtraining_curves.png\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 261\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    258\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCONFIG[\u001b[33m'\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    260\u001b[39m \u001b[38;5;66;03m# Prepare data\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m train_df, val_df, test_df, mlb = \u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m    \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcsv_path\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtarget_column\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    264\u001b[39m num_classes = \u001b[38;5;28mlen\u001b[39m(mlb.classes_)\n\u001b[32m    265\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNumber of classes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 156\u001b[39m, in \u001b[36mprepare_data\u001b[39m\u001b[34m(csv_path, target_column)\u001b[39m\n\u001b[32m    153\u001b[39m mlb.fit([unique_categories])\n\u001b[32m    155\u001b[39m \u001b[38;5;66;03m# Split data\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m train_val_df, test_df = \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtest_size\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\n\u001b[32m    158\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m train_df, val_df = train_test_split(\n\u001b[32m    160\u001b[39m     train_val_df, test_size=CONFIG[\u001b[33m'\u001b[39m\u001b[33mval_size\u001b[39m\u001b[33m'\u001b[39m], random_state=\u001b[32m42\u001b[39m\n\u001b[32m    161\u001b[39m )\n\u001b[32m    163\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTrain: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Val: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(val_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Test: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(test_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2919\u001b[39m, in \u001b[36mtrain_test_split\u001b[39m\u001b[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[39m\n\u001b[32m   2916\u001b[39m arrays = indexable(*arrays)\n\u001b[32m   2918\u001b[39m n_samples = _num_samples(arrays[\u001b[32m0\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m2919\u001b[39m n_train, n_test = \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.25\u001b[39;49m\n\u001b[32m   2921\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2923\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m   2924\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2499\u001b[39m, in \u001b[36m_validate_shuffle_split\u001b[39m\u001b[34m(n_samples, test_size, train_size, default_test_size)\u001b[39m\n\u001b[32m   2496\u001b[39m n_train, n_test = \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[32m   2498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_train == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2499\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2500\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2501\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2502\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33maforementioned parameters.\u001b[39m\u001b[33m\"\u001b[39m.format(n_samples, test_size, train_size)\n\u001b[32m   2503\u001b[39m     )\n\u001b[32m   2505\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[31mValueError\u001b[39m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    'csv_path': os.path.expanduser('~/Downloads/clean_training_data.csv'),\n",
    "    'logo_dir': os.path.expanduser('~/Downloads/logo_images'),\n",
    "    'target_column': 'category_list',  # or 'category_groups_list'\n",
    "    'img_size': 224,\n",
    "    'batch_size': 16,\n",
    "    'num_epochs': 30,\n",
    "    'learning_rate': 0.001,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'num_workers': 0,\n",
    "    'test_size': 0.2,\n",
    "    'val_size': 0.1,\n",
    "}\n",
    "\n",
    "class LogoDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for loading company logos\"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe, logo_dir, mlb, transform=None):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.logo_dir = logo_dir\n",
    "        self.mlb = mlb\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # Get logo filename from the dataframe (pre-matched)\n",
    "        if 'logo_filename' in self.df.columns and pd.notna(row['logo_filename']):\n",
    "            logo_path = os.path.join(self.logo_dir, row['logo_filename'])\n",
    "        else:\n",
    "            # Fallback: try to construct filename from uuid and name\n",
    "            uuid = row['uuid']\n",
    "            name = str(row['name']).replace(' ', '_').replace('/', '_')\n",
    "            \n",
    "            logo_path = None\n",
    "            for ext in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG']:\n",
    "                potential_path = os.path.join(self.logo_dir, f\"{uuid}_{name}{ext}\")\n",
    "                if os.path.exists(potential_path):\n",
    "                    logo_path = potential_path\n",
    "                    break\n",
    "        \n",
    "        if logo_path is None or not os.path.exists(logo_path):\n",
    "            # Return a blank image if logo not found\n",
    "            image = Image.new('RGB', (CONFIG['img_size'], CONFIG['img_size']), color='white')\n",
    "        else:\n",
    "            image = Image.open(logo_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Get multi-label target\n",
    "        categories = row['categories']\n",
    "        if pd.isna(categories) or categories == '':\n",
    "            categories = []\n",
    "        else:\n",
    "            categories = [cat.strip() for cat in str(categories).split(',')]\n",
    "        \n",
    "        label = self.mlb.transform([categories])[0]\n",
    "        \n",
    "        return image, torch.FloatTensor(label)\n",
    "\n",
    "def prepare_data(csv_path, target_column):\n",
    "    \"\"\"Load and prepare the dataset\"\"\"\n",
    "    # Read full CSV first\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Check if target column exists\n",
    "    if target_column not in df.columns:\n",
    "        raise ValueError(f\"Column '{target_column}' not found! Available: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Keep only necessary columns\n",
    "    required_cols = ['uuid', 'name', target_column]\n",
    "    df = df[required_cols].copy()\n",
    "    \n",
    "    # Keep only rows with valid categories\n",
    "    df = df[df[target_column].notna()].copy()\n",
    "    df['categories'] = df[target_column]\n",
    "    \n",
    "    # Filter out rows where logo file doesn't exist\n",
    "    valid_rows = []\n",
    "    logo_dir = CONFIG['logo_dir']\n",
    "    \n",
    "    print(\"Checking for existing logo files...\")\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Validating logos\"):\n",
    "        uuid = row['uuid']\n",
    "        name = row['name'].replace(' ', '_').replace('/', '_')\n",
    "        \n",
    "        # Check if logo exists\n",
    "        logo_exists = False\n",
    "        for ext in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG']:\n",
    "            potential_path = os.path.join(logo_dir, f\"{uuid}_{name}{ext}\")\n",
    "            if os.path.exists(potential_path):\n",
    "                logo_exists = True\n",
    "                break\n",
    "        \n",
    "        if logo_exists:\n",
    "            valid_rows.append(idx)\n",
    "    \n",
    "    df = df.loc[valid_rows].reset_index(drop=True)\n",
    "    print(f\"Found {len(df)} samples with existing logos\")\n",
    "    \n",
    "    # Optional: Limit total samples for faster training\n",
    "    if CONFIG.get('max_samples') and len(df) > CONFIG['max_samples']:\n",
    "        df = df.sample(n=CONFIG['max_samples'], random_state=42).reset_index(drop=True)\n",
    "        print(f\"Randomly sampled {CONFIG['max_samples']} samples for faster training\")\n",
    "    \n",
    "    # Extract all unique categories\n",
    "    all_categories = []\n",
    "    for cats in df['categories']:\n",
    "        if pd.notna(cats):\n",
    "            all_categories.extend([cat.strip() for cat in str(cats).split(',')])\n",
    "    \n",
    "    unique_categories = sorted(set(all_categories))\n",
    "    print(f\"Found {len(unique_categories)} unique categories\")\n",
    "    \n",
    "    # Optional: Filter to only top N most common categories\n",
    "    if CONFIG.get('max_categories'):\n",
    "        from collections import Counter\n",
    "        category_counts = Counter(all_categories)\n",
    "        top_categories = [cat for cat, _ in category_counts.most_common(CONFIG['max_categories'])]\n",
    "        \n",
    "        # Keep only rows with at least one top category\n",
    "        def has_top_category(cats):\n",
    "            if pd.isna(cats):\n",
    "                return False\n",
    "            cat_list = [cat.strip() for cat in str(cats).split(',')]\n",
    "            return any(cat in top_categories for cat in cat_list)\n",
    "        \n",
    "        df = df[df['categories'].apply(has_top_category)].reset_index(drop=True)\n",
    "        unique_categories = top_categories\n",
    "        print(f\"Filtered to top {len(unique_categories)} categories, {len(df)} samples remaining\")\n",
    "    \n",
    "    # Create MultiLabelBinarizer\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    mlb.fit([unique_categories])\n",
    "    \n",
    "    # Split data\n",
    "    train_val_df, test_df = train_test_split(\n",
    "        df, test_size=CONFIG['test_size'], random_state=42\n",
    "    )\n",
    "    train_df, val_df = train_test_split(\n",
    "        train_val_df, test_size=CONFIG['val_size'], random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")\n",
    "    \n",
    "    return train_df, val_df, test_df, mlb\n",
    "\n",
    "def get_transforms():\n",
    "    \"\"\"Define image transformations\"\"\"\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((CONFIG['img_size'], CONFIG['img_size'])),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((CONFIG['img_size'], CONFIG['img_size'])),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    return train_transform, val_transform\n",
    "\n",
    "class ResNetClassifier(nn.Module):\n",
    "    \"\"\"ResNet model for multi-label classification\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes, pretrained=True):\n",
    "        super(ResNetClassifier, self).__init__()\n",
    "        self.resnet = models.resnet50(pretrained=pretrained)\n",
    "        \n",
    "        # Replace the final fully connected layer\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_features, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc='Training')\n",
    "    for batch_idx, (images, labels) in enumerate(progress_bar):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        # Update progress bar with current loss\n",
    "        avg_loss = running_loss / ((batch_idx + 1) * images.size(0))\n",
    "        progress_bar.set_postfix({'loss': f'{avg_loss:.4f}'})\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    return epoch_loss\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    \"\"\"Validate the model\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc='Validation'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            preds = torch.sigmoid(outputs) > 0.5\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    accuracy = (all_preds == all_labels).float().mean().item()\n",
    "    \n",
    "    return epoch_loss, accuracy\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main training pipeline\"\"\"\n",
    "    print(f\"Using device: {CONFIG['device']}\")\n",
    "    \n",
    "    # Prepare data\n",
    "    train_df, val_df, test_df, mlb = prepare_data(\n",
    "        CONFIG['csv_path'], CONFIG['target_column']\n",
    "    )\n",
    "    num_classes = len(mlb.classes_)\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "    \n",
    "    # Get transforms\n",
    "    train_transform, val_transform = get_transforms()\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = LogoDataset(train_df, CONFIG['logo_dir'], mlb, train_transform)\n",
    "    val_dataset = LogoDataset(val_df, CONFIG['logo_dir'], mlb, val_transform)\n",
    "    test_dataset = LogoDataset(test_df, CONFIG['logo_dir'], mlb, val_transform)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=CONFIG['batch_size'], \n",
    "        shuffle=True, num_workers=CONFIG['num_workers']\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=CONFIG['batch_size'], \n",
    "        shuffle=False, num_workers=CONFIG['num_workers']\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=CONFIG['batch_size'], \n",
    "        shuffle=False, num_workers=CONFIG['num_workers']\n",
    "    )\n",
    "    \n",
    "    # Initialize model\n",
    "    model = ResNetClassifier(num_classes, pretrained=True)\n",
    "    model = model.to(CONFIG['device'])\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'])\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=3\n",
    "    )\n",
    "    \n",
    "    # Warn if using CPU\n",
    "    if CONFIG['device'] == 'cpu':\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"WARNING: Training on CPU - this will be VERY slow!\")\n",
    "        print(\"Consider using Google Colab (free GPU) or reducing batch size\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    for epoch in range(CONFIG['num_epochs']):\n",
    "        print(f\"\\nEpoch {epoch+1}/{CONFIG['num_epochs']}\")\n",
    "        \n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, CONFIG['device'])\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, CONFIG['device'])\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.4f}\")\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_loss,\n",
    "                'mlb': mlb,\n",
    "                'config': CONFIG\n",
    "            }, 'best_model.pth')\n",
    "            print(\"Saved best model!\")\n",
    "    \n",
    "    # Test evaluation\n",
    "    print(\"\\nEvaluating on test set...\")\n",
    "    test_loss, test_acc = validate(model, test_loader, criterion, CONFIG['device'])\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    # Plot training curves\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Loss')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(val_accuracies, label='Val Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Validation Accuracy')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_curves.png')\n",
    "    print(\"Training curves saved to 'training_curves.png'\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9b0c6f9-ab70-47db-b733-271591f9e4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Checking for existing logo files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating logos: 100%|██████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 9404.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 samples with existing logos\n",
      "Found 0 unique categories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 369\u001b[39m\n\u001b[32m    366\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining curves saved to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtraining_curves.png\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 261\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    258\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUsing device: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCONFIG[\u001b[33m'\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    260\u001b[39m \u001b[38;5;66;03m# Prepare data\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m train_df, val_df, test_df, mlb = \u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m    \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcsv_path\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtarget_column\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    264\u001b[39m num_classes = \u001b[38;5;28mlen\u001b[39m(mlb.classes_)\n\u001b[32m    265\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNumber of classes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 156\u001b[39m, in \u001b[36mprepare_data\u001b[39m\u001b[34m(csv_path, target_column)\u001b[39m\n\u001b[32m    153\u001b[39m mlb.fit([unique_categories])\n\u001b[32m    155\u001b[39m \u001b[38;5;66;03m# Split data\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m train_val_df, test_df = \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtest_size\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\n\u001b[32m    158\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m train_df, val_df = train_test_split(\n\u001b[32m    160\u001b[39m     train_val_df, test_size=CONFIG[\u001b[33m'\u001b[39m\u001b[33mval_size\u001b[39m\u001b[33m'\u001b[39m], random_state=\u001b[32m42\u001b[39m\n\u001b[32m    161\u001b[39m )\n\u001b[32m    163\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTrain: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Val: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(val_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Test: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(test_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2919\u001b[39m, in \u001b[36mtrain_test_split\u001b[39m\u001b[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[39m\n\u001b[32m   2916\u001b[39m arrays = indexable(*arrays)\n\u001b[32m   2918\u001b[39m n_samples = _num_samples(arrays[\u001b[32m0\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m2919\u001b[39m n_train, n_test = \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.25\u001b[39;49m\n\u001b[32m   2921\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2923\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m   2924\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2499\u001b[39m, in \u001b[36m_validate_shuffle_split\u001b[39m\u001b[34m(n_samples, test_size, train_size, default_test_size)\u001b[39m\n\u001b[32m   2496\u001b[39m n_train, n_test = \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[32m   2498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_train == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m2499\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2500\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2501\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2502\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33maforementioned parameters.\u001b[39m\u001b[33m\"\u001b[39m.format(n_samples, test_size, train_size)\n\u001b[32m   2503\u001b[39m     )\n\u001b[32m   2505\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[31mValueError\u001b[39m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    'csv_path': os.path.expanduser('~/Downloads/clean_training_data.csv'),\n",
    "    'logo_dir': os.path.expanduser('~/Downloads/logo_images'),\n",
    "    'target_column': 'category_list',  # or 'category_groups_list'\n",
    "    'img_size': 224,\n",
    "    'batch_size': 16,\n",
    "    'num_epochs': 30,\n",
    "    'learning_rate': 0.001,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'num_workers': 0,\n",
    "    'test_size': 0.2,\n",
    "    'val_size': 0.1,\n",
    "}\n",
    "\n",
    "class LogoDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for loading company logos\"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe, logo_dir, mlb, transform=None):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.logo_dir = logo_dir\n",
    "        self.mlb = mlb\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # Get logo filename from the dataframe (pre-matched)\n",
    "        if 'logo_filename' in self.df.columns and pd.notna(row['logo_filename']):\n",
    "            logo_path = os.path.join(self.logo_dir, row['logo_filename'])\n",
    "        else:\n",
    "            # Fallback: try to construct filename from uuid and name\n",
    "            uuid = row['uuid']\n",
    "            name = str(row['name']).replace(' ', '_').replace('/', '_')\n",
    "            \n",
    "            logo_path = None\n",
    "            for ext in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG']:\n",
    "                potential_path = os.path.join(self.logo_dir, f\"{uuid}_{name}{ext}\")\n",
    "                if os.path.exists(potential_path):\n",
    "                    logo_path = potential_path\n",
    "                    break\n",
    "        \n",
    "        if logo_path is None or not os.path.exists(logo_path):\n",
    "            # Return a blank image if logo not found\n",
    "            image = Image.new('RGB', (CONFIG['img_size'], CONFIG['img_size']), color='white')\n",
    "        else:\n",
    "            image = Image.open(logo_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Get multi-label target\n",
    "        categories = row['categories']\n",
    "        if pd.isna(categories) or categories == '':\n",
    "            categories = []\n",
    "        else:\n",
    "            categories = [cat.strip() for cat in str(categories).split(',')]\n",
    "        \n",
    "        label = self.mlb.transform([categories])[0]\n",
    "        \n",
    "        return image, torch.FloatTensor(label)\n",
    "\n",
    "def prepare_data(csv_path, target_column):\n",
    "    \"\"\"Load and prepare the dataset\"\"\"\n",
    "    # Read full CSV first\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Check if target column exists\n",
    "    if target_column not in df.columns:\n",
    "        raise ValueError(f\"Column '{target_column}' not found! Available: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Keep only necessary columns\n",
    "    required_cols = ['uuid', 'name', target_column]\n",
    "    df = df[required_cols].copy()\n",
    "    \n",
    "    # Keep only rows with valid categories\n",
    "    df = df[df[target_column].notna()].copy()\n",
    "    df['categories'] = df[target_column]\n",
    "    \n",
    "    # Filter out rows where logo file doesn't exist\n",
    "    valid_rows = []\n",
    "    logo_dir = CONFIG['logo_dir']\n",
    "    \n",
    "    print(\"Checking for existing logo files...\")\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Validating logos\"):\n",
    "        uuid = row['uuid']\n",
    "        name = row['name'].replace(' ', '_').replace('/', '_')\n",
    "        \n",
    "        # Check if logo exists\n",
    "        logo_exists = False\n",
    "        for ext in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG']:\n",
    "            potential_path = os.path.join(logo_dir, f\"{uuid}_{name}{ext}\")\n",
    "            if os.path.exists(potential_path):\n",
    "                logo_exists = True\n",
    "                break\n",
    "        \n",
    "        if logo_exists:\n",
    "            valid_rows.append(idx)\n",
    "    \n",
    "    df = df.loc[valid_rows].reset_index(drop=True)\n",
    "    print(f\"Found {len(df)} samples with existing logos\")\n",
    "    \n",
    "    # Optional: Limit total samples for faster training\n",
    "    if CONFIG.get('max_samples') and len(df) > CONFIG['max_samples']:\n",
    "        df = df.sample(n=CONFIG['max_samples'], random_state=42).reset_index(drop=True)\n",
    "        print(f\"Randomly sampled {CONFIG['max_samples']} samples for faster training\")\n",
    "    \n",
    "    # Extract all unique categories\n",
    "    all_categories = []\n",
    "    for cats in df['categories']:\n",
    "        if pd.notna(cats):\n",
    "            all_categories.extend([cat.strip() for cat in str(cats).split(',')])\n",
    "    \n",
    "    unique_categories = sorted(set(all_categories))\n",
    "    print(f\"Found {len(unique_categories)} unique categories\")\n",
    "    \n",
    "    # Optional: Filter to only top N most common categories\n",
    "    if CONFIG.get('max_categories'):\n",
    "        from collections import Counter\n",
    "        category_counts = Counter(all_categories)\n",
    "        top_categories = [cat for cat, _ in category_counts.most_common(CONFIG['max_categories'])]\n",
    "        \n",
    "        # Keep only rows with at least one top category\n",
    "        def has_top_category(cats):\n",
    "            if pd.isna(cats):\n",
    "                return False\n",
    "            cat_list = [cat.strip() for cat in str(cats).split(',')]\n",
    "            return any(cat in top_categories for cat in cat_list)\n",
    "        \n",
    "        df = df[df['categories'].apply(has_top_category)].reset_index(drop=True)\n",
    "        unique_categories = top_categories\n",
    "        print(f\"Filtered to top {len(unique_categories)} categories, {len(df)} samples remaining\")\n",
    "    \n",
    "    # Create MultiLabelBinarizer\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    mlb.fit([unique_categories])\n",
    "    \n",
    "    # Split data\n",
    "    train_val_df, test_df = train_test_split(\n",
    "        df, test_size=CONFIG['test_size'], random_state=42\n",
    "    )\n",
    "    train_df, val_df = train_test_split(\n",
    "        train_val_df, test_size=CONFIG['val_size'], random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")\n",
    "    \n",
    "    return train_df, val_df, test_df, mlb\n",
    "\n",
    "def get_transforms():\n",
    "    \"\"\"Define image transformations\"\"\"\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((CONFIG['img_size'], CONFIG['img_size'])),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((CONFIG['img_size'], CONFIG['img_size'])),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    return train_transform, val_transform\n",
    "\n",
    "class ResNetClassifier(nn.Module):\n",
    "    \"\"\"ResNet model for multi-label classification\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes, pretrained=True):\n",
    "        super(ResNetClassifier, self).__init__()\n",
    "        self.resnet = models.resnet50(pretrained=pretrained)\n",
    "        \n",
    "        # Replace the final fully connected layer\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_features, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc='Training')\n",
    "    for batch_idx, (images, labels) in enumerate(progress_bar):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        # Update progress bar with current loss\n",
    "        avg_loss = running_loss / ((batch_idx + 1) * images.size(0))\n",
    "        progress_bar.set_postfix({'loss': f'{avg_loss:.4f}'})\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    return epoch_loss\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    \"\"\"Validate the model\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc='Validation'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            preds = torch.sigmoid(outputs) > 0.5\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    accuracy = (all_preds == all_labels).float().mean().item()\n",
    "    \n",
    "    return epoch_loss, accuracy\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main training pipeline\"\"\"\n",
    "    print(f\"Using device: {CONFIG['device']}\")\n",
    "    \n",
    "    # Prepare data\n",
    "    train_df, val_df, test_df, mlb = prepare_data(\n",
    "        CONFIG['csv_path'], CONFIG['target_column']\n",
    "    )\n",
    "    num_classes = len(mlb.classes_)\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "    \n",
    "    # Get transforms\n",
    "    train_transform, val_transform = get_transforms()\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = LogoDataset(train_df, CONFIG['logo_dir'], mlb, train_transform)\n",
    "    val_dataset = LogoDataset(val_df, CONFIG['logo_dir'], mlb, val_transform)\n",
    "    test_dataset = LogoDataset(test_df, CONFIG['logo_dir'], mlb, val_transform)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=CONFIG['batch_size'], \n",
    "        shuffle=True, num_workers=CONFIG['num_workers']\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=CONFIG['batch_size'], \n",
    "        shuffle=False, num_workers=CONFIG['num_workers']\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=CONFIG['batch_size'], \n",
    "        shuffle=False, num_workers=CONFIG['num_workers']\n",
    "    )\n",
    "    \n",
    "    # Initialize model\n",
    "    model = ResNetClassifier(num_classes, pretrained=True)\n",
    "    model = model.to(CONFIG['device'])\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'])\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=3\n",
    "    )\n",
    "    \n",
    "    # Warn if using CPU\n",
    "    if CONFIG['device'] == 'cpu':\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"WARNING: Training on CPU - this will be VERY slow!\")\n",
    "        print(\"Consider using Google Colab (free GPU) or reducing batch size\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    for epoch in range(CONFIG['num_epochs']):\n",
    "        print(f\"\\nEpoch {epoch+1}/{CONFIG['num_epochs']}\")\n",
    "        \n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, CONFIG['device'])\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, CONFIG['device'])\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.4f}\")\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_loss,\n",
    "                'mlb': mlb,\n",
    "                'config': CONFIG\n",
    "            }, 'best_model.pth')\n",
    "            print(\"Saved best model!\")\n",
    "    \n",
    "    # Test evaluation\n",
    "    print(\"\\nEvaluating on test set...\")\n",
    "    test_loss, test_acc = validate(model, test_loader, criterion, CONFIG['device'])\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    # Plot training curves\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Loss')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(val_accuracies, label='Val Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Validation Accuracy')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_curves.png')\n",
    "    print(\"Training curves saved to 'training_curves.png'\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb584078-223e-46c1-9e00-818520556bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jchen\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jchen\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LOGO CLASSIFICATION TRAINING\n",
      "============================================================\n",
      "Device: cpu\n",
      "\n",
      "⚠️  WARNING: Training on CPU will be slow!\n",
      "Consider using Google Colab for free GPU access\n",
      "\n",
      "============================================================\n",
      "LOADING DATA\n",
      "============================================================\n",
      "Loading data from: C:\\Users\\jchen/Downloads/clean_training_data.csv\n",
      "✅ Loaded 1000 rows\n",
      "Columns: ['uuid', 'name', 'category_list', 'logo_filename']\n",
      "After filtering: 1000 rows (removed 0)\n",
      "Unique categories: 458\n",
      "Number of classes: 458\n",
      "\n",
      "Splitting data...\n",
      "Train: 720\n",
      "Val: 80\n",
      "Test: 200\n",
      "\n",
      "============================================================\n",
      "CREATING DATASETS\n",
      "============================================================\n",
      "✅ Datasets created\n",
      "\n",
      "============================================================\n",
      "INITIALIZING MODEL\n",
      "============================================================\n",
      "✅ ResNet18 model initialized\n",
      "\n",
      "============================================================\n",
      "STARTING TRAINING\n",
      "============================================================\n",
      "\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|████████████████████████████▏                              | 11/23 [00:05<00:05,  2.33it/s, loss=0.2706]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\2929_Branded.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\2929_Branded.png'\n",
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\4618_Generation Home.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\4618_Generation Home.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████| 23/23 [00:10<00:00,  2.21it/s, loss=0.3090]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  7.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1579\n",
      "Val Loss: 0.0514, Val Accuracy: 0.9906\n",
      "💾 Saved best model!\n",
      "\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  83%|████████████████████████████████████████████████▋          | 19/23 [00:07<00:01,  2.40it/s, loss=0.0493]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\2929_Branded.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\2929_Branded.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  87%|███████████████████████████████████████████████████▎       | 20/23 [00:08<00:01,  2.43it/s, loss=0.0492]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\4618_Generation Home.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\4618_Generation Home.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████| 23/23 [00:09<00:00,  2.44it/s, loss=0.0954]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  7.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0488\n",
      "Val Loss: 0.0469, Val Accuracy: 0.9906\n",
      "💾 Saved best model!\n",
      "\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|████████████████████▊                                       | 8/23 [00:03<00:06,  2.36it/s, loss=0.0476]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\4618_Generation Home.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\4618_Generation Home.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  61%|███████████████████████████████████▉                       | 14/23 [00:05<00:03,  2.40it/s, loss=0.0463]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\2929_Branded.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\2929_Branded.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████| 23/23 [00:09<00:00,  2.43it/s, loss=0.0896]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0458\n",
      "Val Loss: 0.0444, Val Accuracy: 0.9906\n",
      "💾 Saved best model!\n",
      "\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|███████████████████████▍                                    | 9/23 [00:03<00:05,  2.40it/s, loss=0.0463]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\2929_Branded.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\2929_Branded.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|██████████████████████████████▊                            | 12/23 [00:05<00:04,  2.44it/s, loss=0.0458]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\4618_Generation Home.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\4618_Generation Home.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████| 23/23 [00:09<00:00,  2.46it/s, loss=0.0889]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  7.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0455\n",
      "Val Loss: 0.0442, Val Accuracy: 0.9906\n",
      "💾 Saved best model!\n",
      "\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|██▌                                                         | 1/23 [00:00<00:08,  2.49it/s, loss=0.0407]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\2929_Branded.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\2929_Branded.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  87%|███████████████████████████████████████████████████▎       | 20/23 [00:08<00:01,  2.43it/s, loss=0.0451]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\4618_Generation Home.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\4618_Generation Home.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████| 23/23 [00:09<00:00,  2.44it/s, loss=0.0884]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0452\n",
      "Val Loss: 0.0448, Val Accuracy: 0.9906\n",
      "\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|██████████▍                                                 | 4/23 [00:01<00:07,  2.40it/s, loss=0.0456]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\4618_Generation Home.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\4618_Generation Home.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  96%|████████████████████████████████████████████████████████▍  | 22/23 [00:09<00:00,  2.41it/s, loss=0.0450]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\2929_Branded.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\2929_Branded.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████| 23/23 [00:09<00:00,  2.44it/s, loss=0.0881]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0450\n",
      "Val Loss: 0.0447, Val Accuracy: 0.9906\n",
      "\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|███████▊                                                    | 3/23 [00:01<00:08,  2.35it/s, loss=0.0458]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\2929_Branded.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\2929_Branded.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|█████████████████████████▋                                 | 10/23 [00:04<00:05,  2.34it/s, loss=0.0440]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\4618_Generation Home.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\4618_Generation Home.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████| 23/23 [00:09<00:00,  2.43it/s, loss=0.0866]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  7.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0443\n",
      "Val Loss: 0.0452, Val Accuracy: 0.9904\n",
      "\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|█████▏                                                      | 2/23 [00:00<00:08,  2.46it/s, loss=0.0447]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\4618_Generation Home.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\4618_Generation Home.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|██████████▍                                                 | 4/23 [00:01<00:07,  2.42it/s, loss=0.0433]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\2929_Branded.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\2929_Branded.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████| 23/23 [00:09<00:00,  2.47it/s, loss=0.0866]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0442\n",
      "Val Loss: 0.0456, Val Accuracy: 0.9906\n",
      "\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|███████████████████████████████████████████▌               | 17/23 [00:07<00:02,  2.33it/s, loss=0.0425]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\2929_Branded.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\2929_Branded.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  83%|████████████████████████████████████████████████▋          | 19/23 [00:07<00:01,  2.25it/s, loss=0.0426]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\4618_Generation Home.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\4618_Generation Home.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████| 23/23 [00:09<00:00,  2.40it/s, loss=0.0842]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  7.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0431\n",
      "Val Loss: 0.0456, Val Accuracy: 0.9904\n",
      "\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|█████████████████████████████████████████                  | 16/23 [00:06<00:02,  2.48it/s, loss=0.0417]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\2929_Branded.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\2929_Branded.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  87%|███████████████████████████████████████████████████▎       | 20/23 [00:08<00:01,  2.38it/s, loss=0.0420]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\4618_Generation Home.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\4618_Generation Home.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████| 23/23 [00:09<00:00,  2.46it/s, loss=0.0822]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0420\n",
      "Val Loss: 0.0455, Val Accuracy: 0.9904\n",
      "\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|███████▊                                                    | 3/23 [00:01<00:08,  2.40it/s, loss=0.0444]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\4618_Generation Home.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\4618_Generation Home.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|██████████▍                                                 | 4/23 [00:01<00:07,  2.46it/s, loss=0.0436]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\2929_Branded.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\2929_Branded.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████| 23/23 [00:09<00:00,  2.48it/s, loss=0.0817]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  8.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0417\n",
      "Val Loss: 0.0475, Val Accuracy: 0.9901\n",
      "\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|█████████████                                               | 5/23 [00:02<00:07,  2.44it/s, loss=0.0413]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\2929_Branded.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\2929_Branded.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|██████████████████████████████▊                            | 12/23 [00:04<00:04,  2.46it/s, loss=0.0399]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\4618_Generation Home.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\4618_Generation Home.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████| 23/23 [00:09<00:00,  2.46it/s, loss=0.0797]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0407\n",
      "Val Loss: 0.0472, Val Accuracy: 0.9905\n",
      "\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|██████████████████▎                                         | 7/23 [00:02<00:06,  2.38it/s, loss=0.0375]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\2929_Branded.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\2929_Branded.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  96%|████████████████████████████████████████████████████████▍  | 22/23 [00:09<00:00,  2.43it/s, loss=0.0394]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\4618_Generation Home.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\4618_Generation Home.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████| 23/23 [00:09<00:00,  2.47it/s, loss=0.0768]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0393\n",
      "Val Loss: 0.0474, Val Accuracy: 0.9904\n",
      "\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|██▌                                                         | 1/23 [00:00<00:08,  2.56it/s, loss=0.0376]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\4618_Generation Home.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\4618_Generation Home.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|████████████████████▊                                       | 8/23 [00:03<00:06,  2.49it/s, loss=0.0375]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\2929_Branded.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\2929_Branded.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████| 23/23 [00:09<00:00,  2.52it/s, loss=0.0748]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  8.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0382\n",
      "Val Loss: 0.0471, Val Accuracy: 0.9903\n",
      "\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|█████████████████████████▋                                 | 10/23 [00:04<00:05,  2.38it/s, loss=0.0361]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\2929_Branded.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\2929_Branded.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  91%|█████████████████████████████████████████████████████▊     | 21/23 [00:08<00:00,  2.44it/s, loss=0.0370]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\4618_Generation Home.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\4618_Generation Home.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████| 23/23 [00:09<00:00,  2.43it/s, loss=0.0724]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  8.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0370\n",
      "Val Loss: 0.0482, Val Accuracy: 0.9901\n",
      "\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  43%|█████████████████████████▋                                 | 10/23 [00:04<00:05,  2.29it/s, loss=0.0361]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\2929_Branded.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\2929_Branded.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  48%|████████████████████████████▏                              | 11/23 [00:04<00:05,  2.28it/s, loss=0.0361]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\4618_Generation Home.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\4618_Generation Home.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████| 23/23 [00:09<00:00,  2.36it/s, loss=0.0707]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  8.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0361\n",
      "Val Loss: 0.0483, Val Accuracy: 0.9903\n",
      "\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  35%|████████████████████▊                                       | 8/23 [00:03<00:06,  2.39it/s, loss=0.0336]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\4618_Generation Home.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\4618_Generation Home.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  87%|███████████████████████████████████████████████████▎       | 20/23 [00:08<00:01,  2.47it/s, loss=0.0340]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\2929_Branded.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\2929_Branded.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████| 23/23 [00:09<00:00,  2.46it/s, loss=0.0666]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  8.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0340\n",
      "Val Loss: 0.0481, Val Accuracy: 0.9903\n",
      "\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|██▌                                                         | 1/23 [00:00<00:08,  2.53it/s, loss=0.0356]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\4618_Generation Home.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\4618_Generation Home.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  52%|██████████████████████████████▊                            | 12/23 [00:04<00:04,  2.45it/s, loss=0.0337]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\2929_Branded.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\2929_Branded.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████| 23/23 [00:09<00:00,  2.48it/s, loss=0.0648]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0331\n",
      "Val Loss: 0.0489, Val Accuracy: 0.9898\n",
      "\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|██████████████████▎                                         | 7/23 [00:02<00:06,  2.38it/s, loss=0.0329]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\4618_Generation Home.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\4618_Generation Home.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  78%|██████████████████████████████████████████████▏            | 18/23 [00:07<00:02,  2.31it/s, loss=0.0322]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\2929_Branded.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\2929_Branded.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████| 23/23 [00:09<00:00,  2.44it/s, loss=0.0627]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0320\n",
      "Val Loss: 0.0488, Val Accuracy: 0.9903\n",
      "\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|███████████████▋                                            | 6/23 [00:02<00:07,  2.38it/s, loss=0.0302]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\2929_Branded.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\2929_Branded.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|██████████████████▎                                         | 7/23 [00:02<00:06,  2.40it/s, loss=0.0308]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\4618_Generation Home.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\4618_Generation Home.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████████████| 23/23 [00:09<00:00,  2.48it/s, loss=0.0612]\n",
      "Validation: 100%|████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0313\n",
      "Val Loss: 0.0496, Val Accuracy: 0.9900\n",
      "\n",
      "============================================================\n",
      "FINAL EVALUATION\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:  14%|██████████▎                                                             | 1/7 [00:00<00:02,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not load image C:\\Users\\jchen/Downloads/logo_images\\9681_Ardoq.png: cannot identify image file 'C:\\\\Users\\\\jchen/Downloads/logo_images\\\\9681_Ardoq.png'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|████████████████████████████████████████████████████████████████████████| 7/7 [00:02<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0504\n",
      "Test Accuracy: 0.9896\n",
      "\n",
      "📊 Training curves saved to 'training_curves.png'\n",
      "\n",
      "✅ Training complete!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    'csv_path': os.path.expanduser('~/Downloads/clean_training_data.csv'),\n",
    "    'logo_dir': os.path.expanduser('~/Downloads/logo_images'),\n",
    "    'target_column': 'category_list',\n",
    "    'img_size': 128,  # Reduced from 224 (4x faster!)\n",
    "    'batch_size': 32,  # Increased (2x faster)\n",
    "    'num_epochs': 20,  # Reduced from 30\n",
    "    'learning_rate': 0.001,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'num_workers': 0,\n",
    "    'test_size': 0.2,\n",
    "    'val_size': 0.1,\n",
    "    'use_resnet18': True,  # Use smaller model (4x faster than ResNet50)\n",
    "}\n",
    "\n",
    "class LogoDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for loading company logos\"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe, logo_dir, mlb, transform=None):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.logo_dir = logo_dir\n",
    "        self.mlb = mlb\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # Get logo filename directly from the CSV\n",
    "        logo_filename = row['logo_filename']\n",
    "        logo_path = os.path.join(self.logo_dir, logo_filename)\n",
    "        \n",
    "        # Load image with error handling\n",
    "        try:\n",
    "            if os.path.exists(logo_path):\n",
    "                image = Image.open(logo_path).convert('RGB')\n",
    "            else:\n",
    "                print(f\"Warning: Logo not found: {logo_path}\")\n",
    "                image = Image.new('RGB', (CONFIG['img_size'], CONFIG['img_size']), color='white')\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not load image {logo_path}: {e}\")\n",
    "            # Create a blank white image as fallback\n",
    "            image = Image.new('RGB', (CONFIG['img_size'], CONFIG['img_size']), color='white')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Get multi-label target\n",
    "        categories = row['categories']\n",
    "        if pd.isna(categories) or categories == '':\n",
    "            categories = []\n",
    "        else:\n",
    "            categories = [cat.strip() for cat in str(categories).split(',')]\n",
    "        \n",
    "        label = self.mlb.transform([categories])[0]\n",
    "        \n",
    "        return image, torch.FloatTensor(label)\n",
    "\n",
    "def load_and_prepare_data():\n",
    "    \"\"\"Load the clean CSV and prepare for training\"\"\"\n",
    "    print(f\"Loading data from: {CONFIG['csv_path']}\")\n",
    "    \n",
    "    # Load CSV\n",
    "    df = pd.read_csv(CONFIG['csv_path'])\n",
    "    print(f\"✅ Loaded {len(df)} rows\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Verify required columns exist\n",
    "    required = ['name', CONFIG['target_column'], 'logo_filename']\n",
    "    missing = [col for col in required if col not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required columns: {missing}\")\n",
    "    \n",
    "    # Filter out any rows without categories or logos\n",
    "    original_len = len(df)\n",
    "    df = df[df[CONFIG['target_column']].notna()].copy()\n",
    "    df = df[df['logo_filename'].notna()].copy()\n",
    "    \n",
    "    print(f\"After filtering: {len(df)} rows (removed {original_len - len(df)})\")\n",
    "    \n",
    "    if len(df) == 0:\n",
    "        raise ValueError(\"No valid data after filtering!\")\n",
    "    \n",
    "    # Add categories column for easy access\n",
    "    df['categories'] = df[CONFIG['target_column']]\n",
    "    \n",
    "    # Extract all unique categories\n",
    "    all_categories = []\n",
    "    for cats in df['categories']:\n",
    "        if pd.notna(cats):\n",
    "            all_categories.extend([cat.strip() for cat in str(cats).split(',')])\n",
    "    \n",
    "    unique_categories = sorted(set(all_categories))\n",
    "    print(f\"Unique categories: {len(unique_categories)}\")\n",
    "    \n",
    "    # Create MultiLabelBinarizer\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    mlb.fit([unique_categories])\n",
    "    \n",
    "    return df, mlb\n",
    "\n",
    "def split_data(df):\n",
    "    \"\"\"Split data into train/val/test\"\"\"\n",
    "    print(f\"\\nSplitting data...\")\n",
    "    train_val_df, test_df = train_test_split(\n",
    "        df, test_size=CONFIG['test_size'], random_state=42\n",
    "    )\n",
    "    train_df, val_df = train_test_split(\n",
    "        train_val_df, test_size=CONFIG['val_size'], random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"Train: {len(train_df)}\")\n",
    "    print(f\"Val: {len(val_df)}\")\n",
    "    print(f\"Test: {len(test_df)}\")\n",
    "    \n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "def get_transforms():\n",
    "    \"\"\"Define image transformations\"\"\"\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((CONFIG['img_size'], CONFIG['img_size'])),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((CONFIG['img_size'], CONFIG['img_size'])),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    return train_transform, val_transform\n",
    "\n",
    "class ResNetClassifier(nn.Module):\n",
    "    \"\"\"ResNet model for multi-label classification\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes, pretrained=True, use_resnet18=False):\n",
    "        super(ResNetClassifier, self).__init__()\n",
    "        \n",
    "        if use_resnet18:\n",
    "            self.resnet = models.resnet18(pretrained=pretrained)\n",
    "        else:\n",
    "            self.resnet = models.resnet50(pretrained=pretrained)\n",
    "        \n",
    "        # Replace the final fully connected layer\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(num_features, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc='Training')\n",
    "    for batch_idx, (images, labels) in enumerate(progress_bar):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        # Update progress bar with current loss\n",
    "        avg_loss = running_loss / ((batch_idx + 1) * images.size(0))\n",
    "        progress_bar.set_postfix({'loss': f'{avg_loss:.4f}'})\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    return epoch_loss\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    \"\"\"Validate the model\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc='Validation'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            preds = torch.sigmoid(outputs) > 0.5\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    accuracy = (all_preds == all_labels).float().mean().item()\n",
    "    \n",
    "    return epoch_loss, accuracy\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main training pipeline\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"LOGO CLASSIFICATION TRAINING\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Device: {CONFIG['device']}\")\n",
    "    \n",
    "    if CONFIG['device'] == 'cpu':\n",
    "        print(\"\\n⚠️  WARNING: Training on CPU will be slow!\")\n",
    "        print(\"Consider using Google Colab for free GPU access\")\n",
    "    \n",
    "    # Load data\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"LOADING DATA\")\n",
    "    print(\"=\"*60)\n",
    "    df, mlb = load_and_prepare_data()\n",
    "    num_classes = len(mlb.classes_)\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "    \n",
    "    # Split data\n",
    "    train_df, val_df, test_df = split_data(df)\n",
    "    \n",
    "    # Get transforms\n",
    "    train_transform, val_transform = get_transforms()\n",
    "    \n",
    "    # Create datasets\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"CREATING DATASETS\")\n",
    "    print(\"=\"*60)\n",
    "    train_dataset = LogoDataset(train_df, CONFIG['logo_dir'], mlb, train_transform)\n",
    "    val_dataset = LogoDataset(val_df, CONFIG['logo_dir'], mlb, val_transform)\n",
    "    test_dataset = LogoDataset(test_df, CONFIG['logo_dir'], mlb, val_transform)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=CONFIG['batch_size'], \n",
    "        shuffle=True, num_workers=CONFIG['num_workers']\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=CONFIG['batch_size'], \n",
    "        shuffle=False, num_workers=CONFIG['num_workers']\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=CONFIG['batch_size'], \n",
    "        shuffle=False, num_workers=CONFIG['num_workers']\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ Datasets created\")\n",
    "    \n",
    "    # Initialize model\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"INITIALIZING MODEL\")\n",
    "    print(\"=\"*60)\n",
    "    model_name = \"ResNet18\" if CONFIG['use_resnet18'] else \"ResNet50\"\n",
    "    model = ResNetClassifier(num_classes, pretrained=True, use_resnet18=CONFIG['use_resnet18'])\n",
    "    model = model.to(CONFIG['device'])\n",
    "    print(f\"✅ {model_name} model initialized\")\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'])\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=3\n",
    "    )\n",
    "    \n",
    "    # Training loop\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STARTING TRAINING\")\n",
    "    print(\"=\"*60)\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    for epoch in range(CONFIG['num_epochs']):\n",
    "        print(f\"\\nEpoch {epoch+1}/{CONFIG['num_epochs']}\")\n",
    "        \n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, CONFIG['device'])\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, CONFIG['device'])\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.4f}\")\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_loss,\n",
    "                'mlb': mlb,\n",
    "                'config': CONFIG\n",
    "            }, 'best_model.pth')\n",
    "            print(\"💾 Saved best model!\")\n",
    "    \n",
    "    # Test evaluation\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"FINAL EVALUATION\")\n",
    "    print(\"=\"*60)\n",
    "    test_loss, test_acc = validate(model, test_loader, criterion, CONFIG['device'])\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    # Plot training curves\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Loss')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(val_accuracies, label='Val Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Validation Accuracy')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_curves.png')\n",
    "    print(\"\\n📊 Training curves saved to 'training_curves.png'\")\n",
    "    print(\"\\n✅ Training complete!\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c22356c0-ac23-4b8c-b09c-cf558de9b46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 3060\n",
      "cuda\n",
      "C:\\Users\\jchen\\AppData\\Local\\Programs\\Python\\Python313\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a691c688-4421-492b-8b0c-ef05ddb9c58f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
